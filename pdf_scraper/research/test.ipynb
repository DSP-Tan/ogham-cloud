{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import fitz\n",
    "from fitz import Rect\n",
    "\n",
    "from pdf_scraper.block_utils import identify_dual_column, get_block_text, sort_dual_column_blocks\n",
    "from pdf_scraper.block_utils import is_empty_block, clean_blocks, print_block_table, get_block_table, rebox_blocks\n",
    "from pdf_scraper.block_utils import preproc_blocks\n",
    "from pdf_scraper.draw_utils  import get_pink_boundary, get_fill_df, in_the_pink\n",
    "from pdf_scraper.draw_utils  import draw_rectangles_on_page, get_fill_colours\n",
    "from pdf_scraper.line_utils  import get_line_df, print_line_table, get_all_lines\n",
    "from pdf_scraper.page_utils  import get_page_line_df\n",
    "\n",
    "pd.set_option(\"display.float_format\", \"{:.3f}\".format)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x0       x1       y0       y1       dx       dy       type  number  n_lines first_word\n",
      "--------------------------------------------------------------------------------\n",
      "126.36   465.49   53.74    69.76    339.13   16.02    txt   0       1       TEXT 3 – Pl\n",
      "47.94    535.08   73.68    114.96   487.14   41.28    txt   1       3       TEXT 3 cons\n",
      "47.94    540.89   101.82   143.10   492.95   41.28    txt   2       3       Text 3 cons\n",
      "303.12   533.18   137.64   178.92   230.06   41.28    txt   3       3       constellati\n",
      "47.94    281.42   137.64   296.10   233.48   158.46   txt   4       11      Six of them\n",
      "303.12   543.25   191.34   364.50   240.13   173.16   txt   5       12      At night th\n",
      "47.94    277.98   308.52   481.68   230.04   173.16   txt   6       12      Some alien \n",
      "303.12   542.63   376.92   520.74   239.51   143.82   txt   7       10      Soon things\n",
      "47.94    277.85   494.10   608.64   229.91   114.54   txt   8       8       Its beauty \n",
      "308.82   528.84   533.22   742.98   220.02   209.76   img   9       0       --        \n",
      "47.94    281.55   623.46   738.00   233.61   114.54   txt   10      8       At first th\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "level    = \"AL\"\n",
    "year     = 2025\n",
    "fname    = f\"LC002ALP100EV_{year}.pdf\"\n",
    "examDir  = Path.cwd().parent.parent / \"Exams\"  / \"english\" / level\n",
    "pdf_file = examDir / fname\n",
    "\n",
    "\n",
    "doc              = fitz.open(pdf_file)\n",
    "\n",
    "fill_colours     = get_fill_colours(doc)\n",
    "\n",
    "page_width       = doc[1].get_text(\"dict\")[\"width\"]   # This is a document wide thing doesn't need to be per page.\n",
    "page_height      = doc[1].get_text(\"dict\")[\"height\"]   # This is a document wide thing doesn't need to be per page.\n",
    "\n",
    "\n",
    "page             = doc[5]\n",
    "text_dict        = page.get_text(\"dict\",sort=True)\n",
    "page_drawings    = page.get_drawings()\n",
    "blocks           = text_dict[\"blocks\"]\n",
    "\n",
    "\n",
    "\n",
    "bounding_pink    = get_pink_boundary(page_drawings, fill_colours)\n",
    "clean_blocks     = preproc_blocks(blocks, bounding_pink)\n",
    "\n",
    "pink_blocks      = [block for block in clean_blocks if in_the_pink(block[\"bbox\"], bounding_pink) ]\n",
    "pink_lines       = get_all_lines(pink_blocks)\n",
    "pink_df          = get_line_df(pink_lines)\n",
    "\n",
    "print_block_table(pink_blocks)\n",
    "draw_rectangles_on_page(pdf_file, \"out.pdf\", 4,[bounding_pink] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>dL</th>\n",
       "      <th>h</th>\n",
       "      <th>font_size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TEXT 3 – JOURNEY INTO SPACE</td>\n",
       "      <td>27.462</td>\n",
       "      <td>17.734</td>\n",
       "      <td>16.020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>This edited text is adapted from a speech deli...</td>\n",
       "      <td>13.800</td>\n",
       "      <td>13.284</td>\n",
       "      <td>12.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Aeronautics and Space Administration (NASA), K...</td>\n",
       "      <td>12.036</td>\n",
       "      <td>13.284</td>\n",
       "      <td>12.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>extract he acknowledges the history, and outli...</td>\n",
       "      <td>29.244</td>\n",
       "      <td>15.476</td>\n",
       "      <td>12.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>We will start by increasing NASA’s budget by</td>\n",
       "      <td>13.800</td>\n",
       "      <td>13.284</td>\n",
       "      <td>12.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>$6 billion over the next five years.  We will</td>\n",
       "      <td>13.800</td>\n",
       "      <td>13.284</td>\n",
       "      <td>12.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ramp up robotic exploration of the solar system,</td>\n",
       "      <td>13.800</td>\n",
       "      <td>13.284</td>\n",
       "      <td>12.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>including a probe of the Sun’s atmosphere; new</td>\n",
       "      <td>13.800</td>\n",
       "      <td>13.284</td>\n",
       "      <td>12.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>scouting missions to Mars and other destinations</td>\n",
       "      <td>13.800</td>\n",
       "      <td>13.284</td>\n",
       "      <td>12.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>and an advanced telescope to follow Hubble,</td>\n",
       "      <td>13.800</td>\n",
       "      <td>13.284</td>\n",
       "      <td>12.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>allowing us to peer deeper into the universe t...</td>\n",
       "      <td>13.800</td>\n",
       "      <td>13.284</td>\n",
       "      <td>12.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>ever before.</td>\n",
       "      <td>27.600</td>\n",
       "      <td>13.284</td>\n",
       "      <td>12.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>We will increase Earth-based observation to</td>\n",
       "      <td>13.800</td>\n",
       "      <td>13.284</td>\n",
       "      <td>12.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>improve our understanding of our climate and</td>\n",
       "      <td>13.800</td>\n",
       "      <td>13.284</td>\n",
       "      <td>12.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>our world – science that will garner tangible</td>\n",
       "      <td>13.800</td>\n",
       "      <td>13.284</td>\n",
       "      <td>12.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>benefits, helping us to protect our environment</td>\n",
       "      <td>13.800</td>\n",
       "      <td>13.284</td>\n",
       "      <td>12.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>for future generations.  And we will extend the</td>\n",
       "      <td>13.800</td>\n",
       "      <td>13.284</td>\n",
       "      <td>12.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>life of the International Space Station, while</td>\n",
       "      <td>13.800</td>\n",
       "      <td>13.284</td>\n",
       "      <td>12.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>actually using it for its intended purpose:</td>\n",
       "      <td>13.800</td>\n",
       "      <td>13.284</td>\n",
       "      <td>12.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>conducting advanced research that can help</td>\n",
       "      <td>13.800</td>\n",
       "      <td>13.284</td>\n",
       "      <td>12.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>improve the daily lives of people here on Earth,</td>\n",
       "      <td>13.800</td>\n",
       "      <td>13.284</td>\n",
       "      <td>12.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>as well as testing and improving upon our</td>\n",
       "      <td>13.800</td>\n",
       "      <td>13.284</td>\n",
       "      <td>12.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>capabilities in space.</td>\n",
       "      <td>-136.503</td>\n",
       "      <td>13.284</td>\n",
       "      <td>12.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Source:exploringnation.com</td>\n",
       "      <td>14.583</td>\n",
       "      <td>7.771</td>\n",
       "      <td>7.020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Little more than half a century ago in a remote</td>\n",
       "      <td>13.800</td>\n",
       "      <td>13.284</td>\n",
       "      <td>12.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>and desolate region of what is now called</td>\n",
       "      <td>13.800</td>\n",
       "      <td>13.284</td>\n",
       "      <td>12.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Kazakhstan the Soviet Union launched Sputnik,</td>\n",
       "      <td>13.800</td>\n",
       "      <td>13.284</td>\n",
       "      <td>12.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>the first artificial satellite to orbit the Ea...</td>\n",
       "      <td>13.800</td>\n",
       "      <td>13.284</td>\n",
       "      <td>12.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Soviets, it was perceived, had taken the lead ...</td>\n",
       "      <td>13.800</td>\n",
       "      <td>13.284</td>\n",
       "      <td>12.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>race for which we were not yet fully prepared.</td>\n",
       "      <td>13.800</td>\n",
       "      <td>13.284</td>\n",
       "      <td>12.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>But we caught up very quickly.  In the years t...</td>\n",
       "      <td>13.800</td>\n",
       "      <td>13.284</td>\n",
       "      <td>12.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>have followed, the space race inspired a</td>\n",
       "      <td>13.800</td>\n",
       "      <td>13.284</td>\n",
       "      <td>12.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>generation of scientists and innovators.  It has</td>\n",
       "      <td>13.800</td>\n",
       "      <td>13.284</td>\n",
       "      <td>12.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>contributed</td>\n",
       "      <td>0.000</td>\n",
       "      <td>13.284</td>\n",
       "      <td>12.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>to</td>\n",
       "      <td>0.000</td>\n",
       "      <td>13.284</td>\n",
       "      <td>12.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>immeasurable</td>\n",
       "      <td>0.000</td>\n",
       "      <td>13.284</td>\n",
       "      <td>12.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>technological</td>\n",
       "      <td>13.800</td>\n",
       "      <td>13.284</td>\n",
       "      <td>12.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>advances that have improved our health and well-</td>\n",
       "      <td>13.800</td>\n",
       "      <td>13.284</td>\n",
       "      <td>12.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>being,</td>\n",
       "      <td>0.000</td>\n",
       "      <td>13.284</td>\n",
       "      <td>12.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>from satellite navigation to</td>\n",
       "      <td>0.000</td>\n",
       "      <td>13.284</td>\n",
       "      <td>12.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 text       dL      h  \\\n",
       "0                        TEXT 3 – JOURNEY INTO SPACE    27.462 17.734   \n",
       "1   This edited text is adapted from a speech deli...   13.800 13.284   \n",
       "2   Aeronautics and Space Administration (NASA), K...   12.036 13.284   \n",
       "3   extract he acknowledges the history, and outli...   29.244 15.476   \n",
       "4       We will start by increasing NASA’s budget by    13.800 13.284   \n",
       "5      $6 billion over the next five years.  We will    13.800 13.284   \n",
       "6   ramp up robotic exploration of the solar system,    13.800 13.284   \n",
       "7     including a probe of the Sun’s atmosphere; new    13.800 13.284   \n",
       "8   scouting missions to Mars and other destinations    13.800 13.284   \n",
       "9        and an advanced telescope to follow Hubble,    13.800 13.284   \n",
       "10  allowing us to peer deeper into the universe t...   13.800 13.284   \n",
       "11                                      ever before.    27.600 13.284   \n",
       "12       We will increase Earth-based observation to    13.800 13.284   \n",
       "13      improve our understanding of our climate and    13.800 13.284   \n",
       "14     our world – science that will garner tangible    13.800 13.284   \n",
       "15   benefits, helping us to protect our environment    13.800 13.284   \n",
       "16   for future generations.  And we will extend the    13.800 13.284   \n",
       "17    life of the International Space Station, while    13.800 13.284   \n",
       "18       actually using it for its intended purpose:    13.800 13.284   \n",
       "19        conducting advanced research that can help    13.800 13.284   \n",
       "20  improve the daily lives of people here on Earth,    13.800 13.284   \n",
       "21         as well as testing and improving upon our    13.800 13.284   \n",
       "22                            capabilities in space.  -136.503 13.284   \n",
       "23                        Source:exploringnation.com    14.583  7.771   \n",
       "24   Little more than half a century ago in a remote    13.800 13.284   \n",
       "25         and desolate region of what is now called    13.800 13.284   \n",
       "26     Kazakhstan the Soviet Union launched Sputnik,    13.800 13.284   \n",
       "27  the first artificial satellite to orbit the Ea...   13.800 13.284   \n",
       "28  Soviets, it was perceived, had taken the lead ...   13.800 13.284   \n",
       "29    race for which we were not yet fully prepared.    13.800 13.284   \n",
       "30  But we caught up very quickly.  In the years t...   13.800 13.284   \n",
       "31          have followed, the space race inspired a    13.800 13.284   \n",
       "32  generation of scientists and innovators.  It has    13.800 13.284   \n",
       "33                                       contributed     0.000 13.284   \n",
       "34                                                to     0.000 13.284   \n",
       "35                                      immeasurable     0.000 13.284   \n",
       "36                                     technological    13.800 13.284   \n",
       "37   advances that have improved our health and well-   13.800 13.284   \n",
       "38                                            being,     0.000 13.284   \n",
       "39                      from satellite navigation to     0.000 13.284   \n",
       "\n",
       "    font_size  \n",
       "0      16.020  \n",
       "1      12.000  \n",
       "2      12.000  \n",
       "3      12.000  \n",
       "4      12.000  \n",
       "5      12.000  \n",
       "6      12.000  \n",
       "7      12.000  \n",
       "8      12.000  \n",
       "9      12.000  \n",
       "10     12.000  \n",
       "11     12.000  \n",
       "12     12.000  \n",
       "13     12.000  \n",
       "14     12.000  \n",
       "15     12.000  \n",
       "16     12.000  \n",
       "17     12.000  \n",
       "18     12.000  \n",
       "19     12.000  \n",
       "20     12.000  \n",
       "21     12.000  \n",
       "22     12.000  \n",
       "23      7.020  \n",
       "24     12.000  \n",
       "25     12.000  \n",
       "26     12.000  \n",
       "27     12.000  \n",
       "28     12.000  \n",
       "29     12.000  \n",
       "30     12.000  \n",
       "31     12.000  \n",
       "32     12.000  \n",
       "33     12.000  \n",
       "34     12.000  \n",
       "35     12.000  \n",
       "36     12.000  \n",
       "37     12.000  \n",
       "38     12.000  \n",
       "39     12.000  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pink_df.h = pink_df.h.map(lambda x: round(x,3))\n",
    "pink_df.dL = pink_df.dL.map(lambda x: round(x,3))\n",
    "pink_df[[\"text\",\"dL\",\"h\",\"font_size\"]].head(40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(13.284)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pink_df.h.mode()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(1.038843721770551)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13.8\n",
      "13.8\n",
      "1.038843721770551\n",
      "-13.79998779296875\n",
      "13.8\n"
     ]
    }
   ],
   "source": [
    "print(pink_df.dL.median())\n",
    "print(pink_df.dL.mode()[0])\n",
    "dL_median = pink_df.dL.median()\n",
    "h_median  = pink_df.h.median()\n",
    "new_line = dL_median/h_median\n",
    "\n",
    "print(dL_median/h_median)\n",
    "x00, y00, x01, y01 = pink_lines[10][\"bbox\"]\n",
    "x10, y10, x11, y11 = pink_lines[11][\"bbox\"]\n",
    "print(y00-y10)\n",
    "print(new_line*h_median)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     314\n",
       "1      57\n",
       "2      57\n",
       "3      92\n",
       "4     166\n",
       "     ... \n",
       "58     57\n",
       "59    324\n",
       "60    324\n",
       "61    324\n",
       "62     75\n",
       "Name: x0, Length: 63, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pink_df.x0.map(lambda x : round(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "1. Look at the widths of all pages.\n",
    "2. Create a bin range based on this, and then do the binning.\n",
    "3. Then you can look at this binning altogether all at once.\n",
    "4. Then you can use these bins for further processing and identification of dual columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[298.46636962890625, 298.55999755859375, 298.5264587402344, 298.46875, 298.532470703125, 298.5528869628906, 298.48797607421875, 298.56964111328125, 298.5480041503906, 298.54205322265625, 295.26727294921875]\n",
      "[298.55999755859375, 298.5264587402344, 298.46875, 298.532470703125, 298.5528869628906, 298.48797607421875, 298.56964111328125, 298.5480041503906, 298.54205322265625, 295.26727294921875]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "val_counts = pink_df.x1.value_counts()\n",
    "def bin_values(val_counts, bin_width=10):\n",
    "    '''\n",
    "    make bins around values. If two values are within bin_width of each other,\n",
    "    they get both put into a bin centred on the average of them.\n",
    "    '''\n",
    "    # what we want is to take most present values, and then merge into them all\n",
    "    # other values that are within bin_width of them up or down.\n",
    "    #\n",
    "    # So if we could take the first value, make a sublist of all things within bin_width from it,\n",
    "    # then remove this value and all the values in the sublist from the original list\n",
    "    # continue the loop over the list.\n",
    "\n",
    "    # Maybe you could use a recursive function for that?\n",
    "    x      = val_counts.index.values\n",
    "    counts = val_counts.values\n",
    "    for i in range(2):#range(len(x)):\n",
    "        sublist = [float(x[i])]\n",
    "        for j in range(i+1,len(x)):\n",
    "            if abs(x[i]-x[j]) < bin_width:\n",
    "                #print(x[i],x[j], (x[i]+x[j])/2)\n",
    "                sublist.append(float(x[j]))\n",
    "        print(sublist)\n",
    "bin_values(val_counts,6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.cluster.hierarchy import fclusterdata\n",
    "\n",
    "x = pink_df.x1.value_counts()\n",
    "# Cluster by proximity (within 5 units)\n",
    "data = x.index.to_numpy().reshape(-1, 1)\n",
    "groups = fclusterdata(data, t=5, criterion='distance')\n",
    "\n",
    "# Build a DataFrame for easier grouping\n",
    "df = pd.DataFrame({'x0': x.index, 'count': x.values, 'group': groups})\n",
    "\n",
    "# Group by cluster and compute sum and mean label\n",
    "grouped = df.groupby('group').agg(\n",
    "    total_count=('count', 'sum'),\n",
    "    mean_x0=('x0', 'mean')\n",
    ")\n",
    "\n",
    "# Set the mean x0 as index\n",
    "result = grouped.set_index('mean_x0')['total_count'].sort_values(ascending=False)\n",
    "\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_clean_bins(x:pd.Series,bin_width):\n",
    "    min = x.min()\n",
    "    max = x.max()\n",
    "\n",
    "    bins = np.arange(start=min-bin_width/2, stop=max + 2*bin_width, step=bin_width)\n",
    "\n",
    "    x_binned = pd.cut(x, bins=bins).apply(lambda i: i.mid).value_counts()\n",
    "\n",
    "    return x_binned[x_binned !=0]\n",
    "\n",
    "get_clean_bins(pink_df.x1,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts = df.x0.value_counts()\n",
    "xs     = counts.index.values\n",
    "\n",
    "xl   = xs[0]          if xs[0] < xs[1] else xs[1]\n",
    "n_xl = counts.iloc[0] if xs[0] < xs[1] else counts.iloc[1]\n",
    "xr = xs[0]            if xs[0] > xs[1] else xs[1]\n",
    "n_xr = counts.iloc[0] if xs[0] > xs[1] else counts.iloc[1]\n",
    "\n",
    "third   = np.nan if len(xs) <3 else xs[2]\n",
    "n_third = np.nan if len(xs) <3 else counts.iloc[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "year = 2010\n",
    "fname = f\"LC002ALP100EV_{year}.pdf\"\n",
    "examDir=Path.cwd().parent.parent / \"Exams\"  / \"english\" / level\n",
    "pdf_file = examDir / fname\n",
    "\n",
    "\n",
    "doc              = fitz.open(pdf_file)\n",
    "page2_drawings   = doc[1].get_drawings()\n",
    "fill_colour      = get_fill_df(page2_drawings).fill.mode().values[0]\n",
    "\n",
    "xs = []\n",
    "for page in doc[1:7]:\n",
    "    text_dict        = page.get_text(\"dict\",sort=True)\n",
    "    page_drawings    = page.get_drawings()\n",
    "    blocks           = text_dict[\"blocks\"]\n",
    "\n",
    "    bounding_pink    = get_pink_boundary(page_drawings, fill_colour)\n",
    "    clean_blocks     = preproc_blocks(blocks, bounding_pink)\n",
    "\n",
    "    pink_blocks      = [block for block in clean_blocks if in_the_pink(block[\"bbox\"], bounding_pink) ]\n",
    "    pink_lines       = get_all_lines(pink_blocks)\n",
    "    pink_df          = get_line_df(pink_lines)\n",
    "    #xs.append(pink_df.x0.value_counts())\n",
    "    x2 =pink_df.x0.value_counts().index.values[:2]\n",
    "    xl = x2[0] if x2[0] < x2[1] else x2[1]\n",
    "    xr = x2[0] if x2[0] > x2[1] else x2[1]\n",
    "    xs.append({\"xl\":xl,\"xr\":xr})\n",
    "\n",
    "col_df = pd.DataFrame(xs,index=[f'page_{i+2}' for i in range(len(xs))])\n",
    "col_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "year = 2010\n",
    "fname = f\"LC002ALP100EV_{year}.pdf\"\n",
    "examDir=Path.cwd().parent.parent / \"Exams\"  / \"english\" / level\n",
    "pdf_file = examDir / fname\n",
    "\n",
    "\n",
    "doc              = fitz.open(pdf_file)\n",
    "page2_drawings   = doc[1].get_drawings()\n",
    "fill_colour      = get_fill_df(page2_drawings).fill.mode().values[0]\n",
    "\n",
    "xs = []\n",
    "#for page in doc[1:7]:\n",
    "page=doc[2]\n",
    "text_dict        = page.get_text(\"dict\",sort=True)\n",
    "page_drawings    = page.get_drawings()\n",
    "blocks           = text_dict[\"blocks\"]\n",
    "\n",
    "\n",
    "fill_colour2      = get_fill_df(page_drawings).fill.mode().values[0]\n",
    "\n",
    "\n",
    "\n",
    "bounding_pink    = get_pink_boundary(page_drawings, fill_colour)\n",
    "clean_blocks     = preproc_blocks(blocks, bounding_pink)\n",
    "\n",
    "bounding_pink\n",
    "\n",
    "#pink_blocks      = [block for block in clean_blocks if in_the_pink(block[\"bbox\"], bounding_pink) ]\n",
    "#pink_lines       = get_all_lines(pink_blocks)\n",
    "#pink_df          = get_line_df(pink_lines)\n",
    "##xs.append(pink_df.x0.value_counts())\n",
    "#x2 =pink_df.x0.value_counts().index.values[:2]\n",
    "#xl = x2[0] if x2[0] < x2[1] else x2[1]\n",
    "#xr = x2[0] if x2[0] > x2[1] else x2[1]\n",
    "#xs.append({\"xl\":xl,\"xr\":xr})\n",
    "#\n",
    "#col_df = pd.DataFrame(xs,index=[f'page_{i+2}' for i in range(len(xs))])\n",
    "#col_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "definitely_dual_column\n",
    "\n",
    "- width limit\n",
    "- has correct font size\n",
    "- starts within a given tolerance of one of two possibile start positions."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ogham",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

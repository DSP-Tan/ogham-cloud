{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dcc04d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8994196f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import fitz\n",
    "from fitz import Rect\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.metrics import pairwise_distances\n",
    "\n",
    "from pdf_scraper.doc_utils     import open_exam\n",
    "from pdf_scraper.doc_utils     import identify_footers, identify_instructions, identify_subtitles, identify_subsubtitles\n",
    "from pdf_scraper.line_utils    import clean_line_df, get_category_boxes, get_df_bbox\n",
    "from pdf_scraper.doc_utils     import get_images, filter_images, assign_in_image_captions, identify_vertical_captions\n",
    "from pdf_scraper.doc_utils     import enrich_doc_df_with_images, identify_page_clusters, get_lines_in_image_clusters, preproc_images\n",
    "from pdf_scraper.clustering.cluster_utils import get_vert_neigh_dist, split_cluster, hdbscan, find_y0_dL, correct_eps_y_scale,get_eps_x, get_eps_y\n",
    "from pdf_scraper.general_utils import df_bbox_dist, df_bbox_next_row_dist\n",
    "from pdf_scraper.image_utils   import (get_bboxed_page_image, show_all_imgs, show_image, \n",
    "                                       filter_horizontal_strips, filter_point_images, filter_low_res_doubles,\n",
    "                                       reconstitute_strips, sort_images)\n",
    "\n",
    "pd.set_option(\"display.float_format\", \"{:.2f}\".format)\n",
    "pd.set_option(\"display.max_colwidth\", 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9de93f5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_year_images(year, page, x_scale, y_scale):\n",
    "\n",
    "    doc    = open_exam(year, \"english\", \"al\",1)\n",
    "    images = get_images(doc)\n",
    "    images = filter_images(images)\n",
    "    assign_in_image_captions(df,images)\n",
    "    \n",
    "    df = clean_line_df(df)\n",
    "    df = enrich_doc_df_with_images(df,images)\n",
    "\n",
    "    \n",
    "    page_df = df.loc[df.page==page, [\"text\", 'x0', 'y0', 'x1', 'y1', \"page\",\"w\",\"category\"]].copy()\n",
    "    \n",
    "    x_scale, y_scale = 2.0/3.0 , 1.15\n",
    "    eps_y = get_eps_y(page_df, page, y_scale)\n",
    "    eps_x = get_eps_x(page_df, page, x_scale)\n",
    "    \n",
    "    print(f\"eps_x: {eps_x:<8.2f} eps_y: {eps_y:<8.2f} eps_y scale:{y_scale:4.2f}\")\n",
    "    \n",
    "    rectangs, labia = hdbscan(page_df, 100, eps_x, eps_y, df_bbox_dist,False)\n",
    "    imgs = [get_bboxed_page_image(doc, page, rectangies,color=(0.0,0,0.0), labels=labelos) for rectangies, labelos in zip(rectangs, labia)]\n",
    "    display(imgs[-1])\n",
    "    return rectangs, labia"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef1df30f",
   "metadata": {},
   "source": [
    "# Split images"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4b6bb01",
   "metadata": {},
   "source": [
    "This will be similar to the stripped images issue we have already dealt with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "168779a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc    = open_exam(2005, \"english\", \"al\",1)\n",
    "images = get_images(doc)\n",
    "images = preproc_images(images)\n",
    "show_all_imgs(3,5,images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cda9acac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_contiguous_image_pairs(images, tol) -> list[list[dict]]:\n",
    "    contiguous_image_pairs = []\n",
    "    for i in range(len(images)):\n",
    "        for j in range(i+1,len(images)):\n",
    "            im_a, im_b  = images[i], images[j]\n",
    "            x0_a, y0_a, x1_a, y1_a = im_a[\"bbox\"]\n",
    "            x0_b, y0_b, x1_b, y1_b = im_b[\"bbox\"]\n",
    "    \n",
    "            same_page = im_a[\"page\"] == im_b[\"page\"]\n",
    "            same_x    = (x0_a==x0_b and x1_a ==x1_b)\n",
    "    \n",
    "            a_bellow = (y1_a <= y0_b+tol and y1_a >= y0_b-tol)\n",
    "            a_on_top = (y1_b <= y0_a+tol and y1_b >= y0_a-tol)\n",
    "            top_bottom_touch = a_bellow or a_on_top\n",
    "    \n",
    "            if same_page and same_x and top_bottom_touch:\n",
    "                contiguous_image_pairs.append([im_a,im_b] )\n",
    "    return contiguous_image_pairs\n",
    "\n",
    "def merge_contiguous_pair_lists(contiguous_image_pairs):\n",
    "    \"\"\"\n",
    "    Merge contiguous image pairs (like [1,2], [2,3]) into full groups ([1,2,3]).\n",
    "    Keeps groups separate by page.\n",
    "    \"\"\"\n",
    "    merged = []\n",
    "\n",
    "    images = [img for im_pair in contiguous_image_pairs for img in im_pair] \n",
    "    pair_numbers = [[a[\"number\"],b[\"number\"]] for a, b in contiguous_image_pairs]\n",
    "    \n",
    "    for pair in pair_numbers:\n",
    "        added = False\n",
    "        for group in merged:\n",
    "            page_pair  = next(im[\"page\"] for im in images if im[\"number\"]==pair[0])\n",
    "            page_group = next(im[\"page\"] for im in images if im[\"number\"] in group)\n",
    "            if page_group != page_pair:\n",
    "                continue\n",
    "\n",
    "            if any(x in group for x in pair):\n",
    "                group.update(pair)\n",
    "                added = True\n",
    "                break\n",
    "        if not added:\n",
    "            merged.append(set(pair))  \n",
    "    \n",
    "    merged_ids = [sorted(list(g)) for g in merged]\n",
    "    image_lookup = {im[\"number\"]: im for im in images}\n",
    "    contiguous_image_groups = [ [image_lookup[id] for id in id_list] for id_list in merged_ids]\n",
    "    contiguous_image_groups = [ sort_images(img_list) for img_list in contiguous_image_groups]\n",
    "    \n",
    "\n",
    "    return contiguous_image_groups\n",
    "\n",
    "def identify_contiguous_images(images):\n",
    "    contiguous_image_pairs= find_contiguous_image_pairs(images,0.01)\n",
    "    contiguous_image_groups= merge_contiguous_pair_lists(contiguous_image_pairs)\n",
    "    return contiguous_image_groups\n",
    "\n",
    "\n",
    "merged= identify_contiguous_images(images)\n",
    "print([[im[\"number\"] for im in im_list] for im_list in merged] )\n",
    "\n",
    "fart = identify_contiguous_images(merged[0])[0]\n",
    "print([im[\"number\"] for im in fart] )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61fa249c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pdf_scraper.image_utils import is_horizontal_strip\n",
    "import io \n",
    "def stitch_strips(image_blocks: list[dict]) -> dict:\n",
    "    \"\"\"\n",
    "    Stitch a list of horizontal image strips (already sorted top-to-bottom) into a single image.\n",
    "    Return a dictionary mimicking a fitz text block.\n",
    "    \"\"\"\n",
    "    # check if strips or contiguous:\n",
    "    strip_blocks = [strip for strip in image_blocks if is_horizontal_strip(strip)]\n",
    "    if not strip_blocks:\n",
    "        strip_blocks = identify_contiguous_images(image_blocks)[0]\n",
    "    if not strip_blocks:\n",
    "        return image_blocks\n",
    "\n",
    "    images = [Image.open(io.BytesIO(block[\"image\"])) for block in strip_blocks]\n",
    "\n",
    "    total_height = sum(img.height for img in images)\n",
    "    max_width    = max(img.width for img in images)\n",
    "\n",
    "    stitched = Image.new(\"RGB\", (max_width, total_height), (255, 255, 255))\n",
    "    offset = 0\n",
    "    for img in images:\n",
    "        stitched.paste(img, (0, offset))\n",
    "        offset += img.height\n",
    "\n",
    "    img_byte_arr = io.BytesIO()\n",
    "    stitched.save(img_byte_arr, format='PNG')\n",
    "    img_bytes = img_byte_arr.getvalue()\n",
    "    stitched.close(); img_byte_arr.close()\n",
    "\n",
    "    min_number = min(block[\"number\"]  for block in image_blocks)\n",
    "    min_x0     = min(block[\"bbox\"][0] for block in image_blocks)\n",
    "    min_y0     = min(block[\"bbox\"][1] for block in image_blocks)\n",
    "    max_x1     = max(block[\"bbox\"][2] for block in image_blocks)\n",
    "    max_y1     = max(block[\"bbox\"][3] for block in image_blocks)\n",
    "    bbox = (min_x0, min_y0, max_x1, max_y1)\n",
    "\n",
    "    img_block = image_blocks[0].copy()\n",
    "    img_block[\"number\"]=min_number\n",
    "    img_block[\"bbox\"]=bbox\n",
    "    img_block['width']= stitched.width\n",
    "    img_block['height']= stitched.height\n",
    "    img_block['size']= len(img_bytes)\n",
    "    img_block['image']= img_bytes\n",
    "    #'transform': ref_block.get('transform', (1.0, 0.0, 0.0, 1.0, min_x0, min_y0)),\n",
    "\n",
    "    return img_block\n",
    "\n",
    "def reconstitute_split_images(image_blocks: dict):\n",
    "    split_images = identify_contiguous_images(image_blocks)\n",
    "    split_ids    = [img[\"number\"] for im_group in split_images for img in im_group] \n",
    "\n",
    "    stitched = [stitch_strips(group) for group in split_images]\n",
    "    filtered_blocks = [img for img in image_blocks if img[\"number\"] not in split_ids]\n",
    "    filtered_blocks.extend(stitched)\n",
    "    filtered_blocks.sort(key=lambda x: (x[\"page\"], x[\"bbox\"][1]))\n",
    "    return filtered_blocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdba4d33",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc    = open_exam(2005, \"english\", \"al\",1)\n",
    "images = get_images(doc)\n",
    "images = preproc_images(images)\n",
    "images = reconstitute_split_images(images)\n",
    "show_all_imgs(1,5,images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ad5ebb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc    = open_exam(2005, \"english\", \"al\",1)\n",
    "images = get_images(doc)\n",
    "print(\"before\")\n",
    "show_all_imgs(3,5,images)\n",
    "#images = filter_images(images)\n",
    "#images = reconstitute_split_images(images)\n",
    "images = filter_images(images)\n",
    "print(\"after\")\n",
    "show_all_imgs(1,5,images)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05ec0782",
   "metadata": {},
   "source": [
    "# Low resolution image doubles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7e82e70",
   "metadata": {},
   "outputs": [],
   "source": [
    "def old_filter_images(images):\n",
    "    if len(images) > 100:\n",
    "        images=filter_point_images(images)\n",
    "    if len(images) > 100:\n",
    "        images = reconstitute_strips(images)\n",
    "    return images\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3fce818",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc    = open_exam(2011, \"english\", \"al\",1)\n",
    "images = get_images(doc)\n",
    "images = old_filter_images(images)\n",
    "show_all_imgs(3,3,images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fdccf81",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(images[0][\"bbox\"], images[0][\"size\"])\n",
    "print(images[1][\"bbox\"], images[1][\"size\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf8a5415",
   "metadata": {},
   "outputs": [],
   "source": [
    "images[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a594ecbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_low_res_doubles(images):\n",
    "    images_to_drop = []\n",
    "    for i in range(len(images)):\n",
    "        for j in range(i+1,len(images)):\n",
    "            im1, im2  = images[i], images[j]\n",
    "            if im2[\"bbox\"]==im1[\"bbox\"]:\n",
    "                images_to_drop.append( im1[\"number\"] if im1[\"size\"] > im2[\"size\"] else im2[\"number\"])\n",
    "    return [im for im in images if im[\"number\"] not in images_to_drop]\n",
    "filtered_images = filter_low_res_doubles(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02342f18",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_all_imgs(3,3,filtered_images)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ogham",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

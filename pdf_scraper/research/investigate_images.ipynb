{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dcc04d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8994196f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from pdf_scraper.doc_utils     import open_exam, get_images\n",
    "from pdf_scraper.image_utils   import (show_all_imgs, show_image, filter_point_images, filter_low_res_doubles,\n",
    "                                       find_contiguous_image_pairs, merge_contiguous_pair_lists, stitch_strips,\n",
    "                                       reconstitute_split_images, sort_and_rename_images)\n",
    "\n",
    "\n",
    "pd.set_option(\"display.float_format\", \"{:.2f}\".format)\n",
    "pd.set_option(\"display.max_colwidth\", 200)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "960e5de6",
   "metadata": {},
   "source": [
    "# Stripped and split Images"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7e3d186",
   "metadata": {},
   "source": [
    "When we extract images from the pdf, sometimes these images are split into vertical bands. We would like\n",
    "to join these images back together as the existence of such bands will interfere with code further down the \n",
    "pipeline, in particular captioning code, and also it is just messy. If it is one image let us store it as one\n",
    "image with one id."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2030561f",
   "metadata": {},
   "source": [
    "## Find Stripped Images\n",
    "\n",
    "To find which years have stripped images, let us get the images of many years, filter the point images, and see if there\n",
    "remains some years that have lots of images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f27e32cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(f\"{'year':<8} {'n_raw_images':<18} {'n_images':<18} {'n_split_images':<18}\")\n",
    "for year in range(2001,2026):\n",
    "    doc    = open_exam(year, \"english\", \"al\",1)\n",
    "    images = get_images(doc)\n",
    "    n_raw_images = len(images)\n",
    "    images = filter_point_images(images)\n",
    "    images = filter_low_res_doubles(images)\n",
    "    images = sort_and_rename_images(images)\n",
    "\n",
    "    contig_pairs = find_contiguous_image_pairs(images, 0.01)\n",
    "    split_images = merge_contiguous_pair_lists(contig_pairs)\n",
    "    print(f\"{year:<8} {n_raw_images:<18} {len(images):<18} {len(split_images):<18}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eab7eeb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we can see 2007 and 2013 have stripped images.\n",
    "# 2005, 2006, and 2007 have these point-image artifacts which must be removed.\n",
    "# 2009 is a special case as it has two split images on the same page. It can be used to test robustness of code."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2041033",
   "metadata": {},
   "source": [
    "In the examinations of images below, to see the problems being solved, uncomment the commented code."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dff4a94d",
   "metadata": {},
   "source": [
    "## Examine 2007\n",
    "This has an image on page 3 split into a good number of strips."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fb65e5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "year=2007\n",
    "doc    = open_exam(year, \"english\", \"al\",1)\n",
    "images = get_images(doc)\n",
    "images = filter_point_images(images)\n",
    "images = filter_low_res_doubles(images)\n",
    "images = sort_and_rename_images(images)\n",
    "print(f\"{year}: {len(images)}\")\n",
    "\n",
    "#show_all_imgs(6, 4,images[2:])\n",
    "#contig_pairs = find_contiguous_image_pairs(images, 0.01)\n",
    "#print(len(contig_pairs))\n",
    "\n",
    "#split_images = merge_contiguous_pair_lists(contig_pairs)\n",
    "#print(len(split_images))\n",
    "\n",
    "#stitched = [stitch_strips(group) for group in split_images]\n",
    "\n",
    "from pdf_scraper.image_utils import reconstitute_split_images\n",
    "\n",
    "images = reconstitute_split_images(images)\n",
    "\n",
    "print(f\"{year}: {len(images)}\")\n",
    "show_all_imgs(2, 3,images)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74ed1bbd",
   "metadata": {},
   "source": [
    "## Examine 2013"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ae7f9f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "year=2013\n",
    "doc    = open_exam(year, \"english\", \"al\",1)\n",
    "images = get_images(doc)\n",
    "images = filter_point_images(images)\n",
    "images = filter_low_res_doubles(images)\n",
    "images = sort_and_rename_images(images)\n",
    "print(f\"{year}: {len(images)}\")\n",
    "\n",
    "#show_all_imgs(3, 4,images[2:])\n",
    "\n",
    "#contig_pairs = find_contiguous_image_pairs(images, 0.01)\n",
    "#print(len(contig_pairs))\n",
    "\n",
    "#split_images = merge_contiguous_pair_lists(contig_pairs)\n",
    "#print(len(split_images))\n",
    "\n",
    "\n",
    "#stitched = [stitch_strips(group) for group in split_images]\n",
    "#show_image(stitched[0])\n",
    "\n",
    "images= reconstitute_split_images(images)\n",
    "print(f\"{year}: {len(images)}\")\n",
    "show_all_imgs(2, 3,images)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3755d83d",
   "metadata": {},
   "source": [
    "## Examine 2009"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d071f52",
   "metadata": {},
   "outputs": [],
   "source": [
    "year=2009\n",
    "doc    = open_exam(year, \"english\", \"al\",1)\n",
    "images = get_images(doc)\n",
    "images = filter_point_images(images)\n",
    "images = filter_low_res_doubles(images)\n",
    "images = sort_and_rename_images(images)\n",
    "print(f\"{year}: {len(images)}\")\n",
    "\n",
    "#show_all_imgs(3, 4,images[2:])\n",
    "#\n",
    "#contig_pairs = find_contiguous_image_pairs(images, 0.01)\n",
    "#print(len(contig_pairs))\n",
    "#\n",
    "#split_images = merge_contiguous_pair_lists(contig_pairs)\n",
    "#print(len(split_images))\n",
    "#\n",
    "#\n",
    "#stitched = [stitch_strips(group) for group in split_images]\n",
    "#show_all_imgs(1,3,stitched)\n",
    "\n",
    "images = reconstitute_split_images(images)\n",
    "show_all_imgs(2,3,images)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05ec0782",
   "metadata": {},
   "source": [
    "# Low resolution image doubles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7e82e70",
   "metadata": {},
   "outputs": [],
   "source": [
    "def old_filter_images(images):\n",
    "    if len(images) > 100:\n",
    "        images=filter_point_images(images)\n",
    "    if len(images) > 10:\n",
    "        images = reconstitute_split_images(images)\n",
    "    return images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3fce818",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc    = open_exam(2011, \"english\", \"al\",1)\n",
    "images = get_images(doc)\n",
    "images = old_filter_images(images)\n",
    "show_all_imgs(3,3,images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fdccf81",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(images[0][\"bbox\"], images[0][\"size\"])\n",
    "print(images[1][\"bbox\"], images[1][\"size\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf8a5415",
   "metadata": {},
   "outputs": [],
   "source": [
    "images[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a594ecbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_low_res_doubles(images):\n",
    "    images_to_drop = []\n",
    "    for i in range(len(images)):\n",
    "        for j in range(i+1,len(images)):\n",
    "            im1, im2  = images[i], images[j]\n",
    "            if im2[\"bbox\"]==im1[\"bbox\"]:\n",
    "                images_to_drop.append( im1[\"number\"] if im1[\"size\"] > im2[\"size\"] else im2[\"number\"])\n",
    "    return [im for im in images if im[\"number\"] not in images_to_drop]\n",
    "filtered_images = filter_low_res_doubles(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02342f18",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_all_imgs(3,3,filtered_images)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ogham",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

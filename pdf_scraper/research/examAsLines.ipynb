{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b9242a4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "73bcdb8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from fitz import Rect\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "from pdf_scraper.doc_utils import open_exam, get_images, filter_point_images\n",
    "from pdf_scraper.doc_utils import get_doc_line_df\n",
    "from pdf_scraper.doc_utils import get_captions\n",
    "from pdf_scraper.block_utils import clean_blocks\n",
    "from pdf_scraper.line_utils import print_line_table, get_line_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4edb46b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "from io import BytesIO\n",
    "\n",
    "def show_image(image):\n",
    "    img_bytes = image[\"image\"]\n",
    "    img_stream = BytesIO(img_bytes)\n",
    "    img = Image.open(img_stream)\n",
    "    display(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "048c5180",
   "metadata": {},
   "source": [
    "1. Get all images.\n",
    "   - filter image artifacts and stitch stripped images. \n",
    "2. Get all text lines.\n",
    "3. Identify and Remove captions from text lines.\n",
    "4. Identify and resort dual column text.\n",
    "5. Identify and remove page headers and footers. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "79bbdc68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of raw images                :        260\n",
      "number of images after  point filter:        260\n",
      "        text  page\n",
      "42  IMAGE 1      2\n",
      "        text  page\n",
      "42  IMAGE 1      2\n",
      "        text  page\n",
      "42  IMAGE 1      2\n",
      "        text  page\n",
      "42  IMAGE 1      2\n",
      "        text  page\n",
      "42  IMAGE 1      2\n",
      "        text  page\n",
      "42  IMAGE 1      2\n",
      "        text  page\n",
      "42  IMAGE 1      2\n",
      "        text  page\n",
      "42  IMAGE 1      2\n",
      "        text  page\n",
      "42  IMAGE 1      2\n",
      "        text  page\n",
      "42  IMAGE 1      2\n",
      "        text  page\n",
      "42  IMAGE 1      2\n",
      "        text  page\n",
      "42  IMAGE 1      2\n",
      "        text  page\n",
      "42  IMAGE 1      2\n",
      "        text  page\n",
      "42  IMAGE 1      2\n",
      "        text  page\n",
      "42  IMAGE 1      2\n",
      "        text  page\n",
      "42  IMAGE 1      2\n",
      "        text  page\n",
      "42  IMAGE 1      2\n",
      "        text  page\n",
      "42  IMAGE 1      2\n",
      "         text  page\n",
      "133  IMAGE 2      3\n"
     ]
    }
   ],
   "source": [
    "# 2001 - good\n",
    "# 2002 - non-caption close to image counted as caption. ==> to count as inside we say it must be > 0.2 inside.\n",
    "# 2003 - good\n",
    "# 2004 - good\n",
    "# 2005 - 2 captions, captured but pictures are not all together, they are partitioned in boxes.\n",
    "# 2006 - good -> point artifacts filtered\n",
    "# 2007 - good\n",
    "# 2008 - good\n",
    "# 2009 - good\n",
    "# 2010 - good\n",
    "# 2011 - Captions below images page 2 and 3.\n",
    "# 2012 - Mostly good, then some captions below image.\n",
    "# 2013 - page 3 and 2, image cut into slices, captions overlap with many. page 4 caption below image.\n",
    "# 2014 - caption below image page 3. all others good\n",
    "# 2015 - 2018 good\n",
    "# 2019 - caption not contained in photo.\n",
    "# 2020 - good\n",
    "# 2022 - good\n",
    "# 2023 - good\n",
    "# 2024 - good\n",
    "# 2025 - good\n",
    "# For caption prediction, we should have distance to nearest image\n",
    "# distance to nearest text.\n",
    "year=2013\n",
    "doc = open_exam(year,\"english\",\"al\",1)\n",
    "doc_df = get_doc_line_df(doc)\n",
    "images = get_images(doc)\n",
    "print(f\"number of raw images                : {len(images):10}\")\n",
    "images = filter_point_images(images)\n",
    "print(f\"number of images after  point filter: {len(images):10}\")\n",
    "images = get_captions(doc_df, images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d5ce50de",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bbox_distance(bbox1, bbox2):\n",
    "    \"\"\"\n",
    "    Calculates the minimum edge-to-edge distance between two bounding boxes.\n",
    "    Each box is in [x_min, y_min, x_max, y_max] format.\n",
    "    Returns 0 if they overlap or touch.\n",
    "    \"\"\"\n",
    "    x_min1, y_min1, x_max1, y_max1 = bbox1\n",
    "    x_min2, y_min2, x_max2, y_max2 = bbox2\n",
    "\n",
    "    dx = max(x_min2 - x_max1, x_min1 - x_max2, 0)\n",
    "    dy = max(y_min2 - y_max1, y_min1 - y_max2, 0)\n",
    "\n",
    "    return np.hypot(dx, dy)\n",
    "\n",
    "def closest_image(bbox, images, n_page):\n",
    "    dist = 100000\n",
    "    page_images = [img for img in images if img[\"page\"]==n_page]\n",
    "    for image in page_images:\n",
    "        if (bbox_distance(bbox,image[\"bbox\"])) < dist:\n",
    "            closest=image\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "98207529",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x0</th>\n",
       "      <th>y0</th>\n",
       "      <th>x1</th>\n",
       "      <th>y1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [x0, y0, x1, y1]\n",
       "Index: []"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "IndexError",
     "evalue": "index 0 is out of bounds for axis 0 with size 0",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mIndexError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[89]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m display(doc_df[doc_df.text==\u001b[33m'\u001b[39m\u001b[33mWarstones\u001b[39m\u001b[38;5;130;01m\\xa0\u001b[39;00m\u001b[33mLibrary\u001b[39m\u001b[38;5;130;01m\\xa0\u001b[39;00m\u001b[33m'\u001b[39m][[\u001b[33m\"\u001b[39m\u001b[33mx0\u001b[39m\u001b[33m\"\u001b[39m,\u001b[33m\"\u001b[39m\u001b[33my0\u001b[39m\u001b[33m\"\u001b[39m,\u001b[33m\"\u001b[39m\u001b[33mx1\u001b[39m\u001b[33m\"\u001b[39m,\u001b[33m\"\u001b[39m\u001b[33my1\u001b[39m\u001b[33m\"\u001b[39m]])\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m bbox = \u001b[38;5;28mtuple\u001b[39m(\u001b[43mdoc_df\u001b[49m\u001b[43m[\u001b[49m\u001b[43mdoc_df\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m==\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mWarstones\u001b[39;49m\u001b[38;5;130;43;01m\\xa0\u001b[39;49;00m\u001b[33;43mLibrary\u001b[39;49m\u001b[38;5;130;43;01m\\xa0\u001b[39;49;00m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mx0\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43my0\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mx1\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43my1\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[43m.\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m]\u001b[49m)\n\u001b[32m      4\u001b[39m img = closest_image(bbox,images)\n\u001b[32m      5\u001b[39m img[\u001b[33m\"\u001b[39m\u001b[33mcaption\u001b[39m\u001b[33m\"\u001b[39m]=\u001b[33m'\u001b[39m\u001b[33mWarstones\u001b[39m\u001b[38;5;130;01m\\xa0\u001b[39;00m\u001b[33mLibrary\u001b[39m\u001b[38;5;130;01m\\xa0\u001b[39;00m\u001b[33m'\u001b[39m\n",
      "\u001b[31mIndexError\u001b[39m: index 0 is out of bounds for axis 0 with size 0"
     ]
    }
   ],
   "source": [
    "display(doc_df[doc_df.text=='Warstones\\xa0Library\\xa0'][[\"x0\",\"y0\",\"x1\",\"y1\"]])\n",
    "\n",
    "bbox = tuple(doc_df[doc_df.text=='Warstones\\xa0Library\\xa0'][[\"x0\",\"y0\",\"x1\",\"y1\"]].values[0])\n",
    "img = closest_image(bbox,images)\n",
    "img[\"caption\"]='Warstones\\xa0Library\\xa0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "35065d3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n",
      "254\n",
      "198.17999267578125\n",
      "0.779998779296875\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "page_2_strips = [img for img in images if img[\"page\"]==2]\n",
    "print(len(images)-len(page_2_strips))\n",
    "print(len(page_2_strips))\n",
    "img=page_2_strips[0]\n",
    "x0,y0,x1,y1 = img[\"bbox\"]\n",
    "print(x1-x0)\n",
    "print(y1-y0)\n",
    "threshold=5\n",
    "(x1 - x0) < threshold and (y1 - y0) < threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f3079c25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "254\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([1])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([367])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "page_2_strips = [image for image in images if image[\"page\"]==2  ]\n",
    "print(len(page_2_strips))\n",
    "heights=[strip[\"height\"] for strip in page_2_strips ]\n",
    "widths =[strip[\"width\"] for strip in page_2_strips ]\n",
    "display(np.unique(heights))\n",
    "display(np.unique(widths))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dcfaa9eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def is_horizontal_strip(img):\n",
    "    return img[\"height\"] <2 and img[\"width\"] > 40\n",
    "\n",
    "all([is_horizontal_strip(img) for img in page_2_strips] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "204e7a58",
   "metadata": {},
   "outputs": [],
   "source": [
    "y0s = [img[\"bbox\"][1] for img in page_2_strips]\n",
    "\n",
    "for i in range(len(y0s[:-2]) ):\n",
    "    if y0s[i+1] < y0s[i]:\n",
    "        print(\"not monotonic!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3da1d766",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "74.40249633789062"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc[1].get_text(\"dict\")[\"width\"]/8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7a6a51d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "page_2_images[0][\"caption\"].isspace() or not page_2_images[0][\"caption\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89dd84e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "blocks=[]\n",
    "images = []\n",
    "dfs = []\n",
    "for i, page in enumerate(doc):\n",
    "    page_blocks  = page.get_text(\"dict\",sort=True)[\"blocks\"]\n",
    "\n",
    "    text_blocks  = [block for block in page_blocks if not block[\"type\"]]\n",
    "    text_blocks = clean_blocks(text_blocks)\n",
    "\n",
    "    image_blocks = [block for block in page_blocks if     block[\"type\"]]\n",
    "    for image_block in image_blocks:\n",
    "        image_block[\"page\"]= i+1\n",
    "\n",
    "    page_lines   = [ line for block in text_blocks for line in block[\"lines\"]]\n",
    "    page_df = get_line_df(page_lines)\n",
    "    page_df[\"page\"] = i+1\n",
    "    dfs.append(page_df)\n",
    "\n",
    "grand_df = pd.concat(dfs,ignore_index=True)\n",
    "grand_df[\"dual_col\"]=0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67d7e98f",
   "metadata": {},
   "source": [
    "# label dual column text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ebd3f34",
   "metadata": {},
   "source": [
    "## Label page 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5ddf3bb7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24    SECTION I                       COMPREHENDING ...\n",
       "25                        TEXT 1 – FROM GENRE to GENRE \n",
       "26    This text consists of two elements: firstly, e...\n",
       "27    The Misadventures of a Dithering Writer in Thi...\n",
       "28    writing in different genres.  The second eleme...\n",
       "29    I flit anxiously and eagerly from genre to gen...\n",
       "30    yourself be led by the child that you were.  T...\n",
       "31     I always have a few stories on the go.  Some of \n",
       "32       is a tendency I adhered to upon my resumption \n",
       "33     and, indeed, return to when it all threatens to \n",
       "34     them are like eels – they slip away if I do not \n",
       "35    make a fast grab.  Some are like bold children – \n",
       "36                                   get away from me. \n",
       "37      they pay absolutely no attention to anything I \n",
       "38     tell them to do.  One or two arrive unannounced \n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grand_df[grand_df.page==2].text.head(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06e46040",
   "metadata": {},
   "source": [
    "function\n",
    "- takes in 4 lines: top left, top right, bottom left, bottom right\n",
    "- makes copy of data frame\n",
    "- identifies all lines between these. (max and min index)\n",
    "- sorts this part of the data frame \n",
    "- returns tuple (sorted data frame, indices)\n",
    "\n",
    "Then you can reassign this sorted data frame to the original data frame between\n",
    "the provided indices.\n",
    "\n",
    "Or else it can change the passed data frame in place which would be as useufl. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "82e133b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def setDualCols(grand_df: pd.DataFrame, page_num:int, bookends: tuple[str]):\n",
    "    page_df = grand_df[grand_df.page==page_num].copy()\n",
    "    l1, r1, l2, r2 = bookends\n",
    "    for line in bookends:\n",
    "        print(page_df[page_df.text.str.contains(line)].index)\n",
    "    indices = [page_df[page_df.text.str.contains(line)].index for line in bookends]\n",
    "    top    = min(indices).values[0]\n",
    "    bottom = max(indices).values[0]\n",
    "    dual_cols = page_df[top:bottom+1].copy()\n",
    "    dual_cols.sort_values([\"x0\",\"y0\"],inplace=True)\n",
    "    dual_cols[\"daul_col\"]=1\n",
    "\n",
    "    grand_df.loc[top:bottom+1] = dual_cols\n",
    "\n",
    "    return grand_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "64661fa9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24    SECTION I                       COMPREHENDING ...\n",
       "25                        TEXT 1 – FROM GENRE to GENRE \n",
       "26    This text consists of two elements: firstly, e...\n",
       "27    The Misadventures of a Dithering Writer in Thi...\n",
       "28    writing in different genres.  The second eleme...\n",
       "29    I flit anxiously and eagerly from genre to gen...\n",
       "30    yourself be led by the child that you were.  T...\n",
       "31     I always have a few stories on the go.  Some of \n",
       "32       is a tendency I adhered to upon my resumption \n",
       "33     and, indeed, return to when it all threatens to \n",
       "34     them are like eels – they slip away if I do not \n",
       "35    make a fast grab.  Some are like bold children – \n",
       "36                                   get away from me. \n",
       "37      they pay absolutely no attention to anything I \n",
       "38     tell them to do.  One or two arrive unannounced \n",
       "39      I am, at various times, a reluctant, plodding, \n",
       "40    instinctive, spontaneous writer.  At times I f...\n",
       "41        from the farthest recesses of my imagination \n",
       "42    and insist on writing themselves with little o...\n",
       "43        that, if I stay awake for long enough, I can \n",
       "44     reach the end of a considerable narrative arc.  \n",
       "45     input from myself.  I have four novels to write \n",
       "46            and a couple of plays require open heart \n",
       "47     At other times I feel that uncapping a pen is a \n",
       "48         bridge too far.  I wake and enter every day \n",
       "49     surgery.  Several poems are threatening to rise \n",
       "50     up and bite off my fingers if I don’t give them \n",
       "51             with varying combinations of wonder and \n",
       "52                                              dread. \n",
       "53                              immediate attention.   \n",
       "54             I don’t know if my writing is in anyway \n",
       "55        I have started several novels.  There is the \n",
       "56    distinctive.  I am an aural learner as opposed...\n",
       "57       edgy-existential one about the brother-sister \n",
       "58        assassination squad.  There is the comedy-of-\n",
       "59            say the more common visual learning that \n",
       "60         attends so much writing.  I can hear things \n",
       "61      desperation one about the office slave finally \n",
       "62           tipped over the edge by a boss constantly \n",
       "63      before I see them.  My reasons for writing are \n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grand_df[grand_df.page==2].text.head(40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "67ef4f28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index([29], dtype='int64')\n",
      "Index([30], dtype='int64')\n",
      "Index([106], dtype='int64')\n",
      "Index([107], dtype='int64')\n"
     ]
    }
   ],
   "source": [
    "line_l1 = \"I flit anxious\"\n",
    "line_r1 = \"yourself be led by the child\"\n",
    "line_lf = \"imagination had not abandoned me\"\n",
    "line_rf = \"lose almost all the time\"\n",
    "\n",
    "bookends = [line_l1,line_r1, line_lf, line_rf]\n",
    "\n",
    "grand_df = setDualCols(grand_df, 2, bookends)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "472363c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24    SECTION I                       COMPREHENDING ...\n",
       "25                        TEXT 1 – FROM GENRE to GENRE \n",
       "26    This text consists of two elements: firstly, e...\n",
       "27    The Misadventures of a Dithering Writer in Thi...\n",
       "28    writing in different genres.  The second eleme...\n",
       "53                              immediate attention.   \n",
       "54             I don’t know if my writing is in anyway \n",
       "55        I have started several novels.  There is the \n",
       "56    distinctive.  I am an aural learner as opposed...\n",
       "57       edgy-existential one about the brother-sister \n",
       "58        assassination squad.  There is the comedy-of-\n",
       "59            say the more common visual learning that \n",
       "60         attends so much writing.  I can hear things \n",
       "61      desperation one about the office slave finally \n",
       "62           tipped over the edge by a boss constantly \n",
       "63      before I see them.  My reasons for writing are \n",
       "64    partly intrinsic, partly spiritual, partly fan...\n",
       "65       referred to as the highly evolved vegetable.  \n",
       "66      There is the life-weary one about the last day \n",
       "67    Intrinsic because if I do not write I will go ...\n",
       "68        Spiritual because I like to hang around with \n",
       "69    in the working life of a barber terrified beyond \n",
       "70            measure of the imminent reunion with his \n",
       "71       people who do not exist.  Fanatical because I \n",
       "72         like moving as quickly as possible from the \n",
       "73          poet-activist daughter.  There is my novel \n",
       "74          featuring an as-yet-to-be named antagonist \n",
       "75                everyday world into the world of the \n",
       "76       imagination.  Stretching reality; bending it, \n",
       "77    who is more of a genius in dreams than in life.  \n",
       "78     I am all the time hankering to work on the very \n",
       "79    distorting it, somehow twisting it out of shap...\n",
       "80       Watching what characters make of this tilt in \n",
       "81      project I am not currently tangled up inside.  \n",
       "82            their lives – this is what I like to do. \n",
       "83    If you know what you want to be you will be it.  \n",
       "84    I began writing as a boy.  Little stories, pla...\n",
       "85         If you don’t know, then you will spend your \n",
       "86      days reinventing yourself, discovering who you \n",
       "87               poems.  My early offering was heavily \n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grand_df[grand_df.page==2].text.head(40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "71e0c906",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index([29], dtype='int64')\n",
      "Index([69], dtype='int64')\n",
      "Index([68], dtype='int64')\n",
      "Index([107], dtype='int64')\n"
     ]
    }
   ],
   "source": [
    "page2_df = grand_df[grand_df.page==2].copy()\n",
    "line_l1 = \"I flit anxious\"\n",
    "line_r1 = \"yourself be led by the child\"\n",
    "\n",
    "line_lf = \"imagination had not abandoned me\"\n",
    "line_rf = \"lose almost all the time\"\n",
    "\n",
    "bookends = [line_l1,line_r1, line_lf, line_rf]\n",
    "for line in bookends:\n",
    "    print(page2_df[page2_df.text.str.contains(line)].index)\n",
    "indices = [page2_df[page2_df.text.str.contains(line)].index for line in bookends]\n",
    "top = min(indices)\n",
    "bottom = max(indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "c91dd1ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "page2_text = page2_df[top.values[0]:bottom.values[0]+1].sort_values([\"x0\",\"y0\"])\n",
    "page2_text[\"dual_col\"]=1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6ff3d9d",
   "metadata": {},
   "source": [
    "# Fixing stripped images"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40eb7bc2",
   "metadata": {},
   "source": [
    "We were workin gthrough these functions from chat gpt:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d56d8bec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "343.44000244140625\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "254"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x0s = np.unique([strip[\"bbox\"][0] for strip in page_2_strips])\n",
    "n_strip_images = len(x0s)\n",
    "for x0 in x0s:\n",
    "    print(x0)\n",
    "    strips = [strip for strip in page_2_strips if strip[\"bbox\"][0]==x0]\n",
    "len(strips)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7bfb52ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'number': 9,\n",
       " 'type': 1,\n",
       " 'bbox': (343.44000244140625,\n",
       "  139.62002563476562,\n",
       "  541.6199951171875,\n",
       "  140.4000244140625),\n",
       " 'width': 367,\n",
       " 'height': 1,\n",
       " 'ext': 'png',\n",
       " 'colorspace': 1,\n",
       " 'xres': 96,\n",
       " 'yres': 96,\n",
       " 'bpc': 8,\n",
       " 'transform': (198.17999267578125,\n",
       "  0.0,\n",
       "  -0.0,\n",
       "  0.7799999713897705,\n",
       "  343.44000244140625,\n",
       "  139.62002563476562),\n",
       " 'size': 850,\n",
       " 'image': b'\\x89PNG\\r\\n\\x1a\\n\\x00\\x00\\x00\\rIHDR\\x00\\x00\\x01o\\x00\\x00\\x00\\x01\\x08\\x02\\x00\\x00\\x00\\x9e\\xd7\\xb8\\xdd\\x00\\x00\\x00\\tpHYs\\x00\\x00\\x0e\\xc4\\x00\\x00\\x0e\\xc4\\x01\\x95+\\x0e\\x1b\\x00\\x00\\x03\\x04IDATx\\x9c5\\x92\\xeb+\\xe4a\\x14\\xc7\\xf7? f\\x18\\x96q\\x19E./\\xdc\\xd92\\x841\\xc4\\xc8u\\xdc\\x19\\xb2\\xe6\\r!\\xb4V\\xe1\\x1d\\xf1f\\x0b\\xf1b\\xcb5\\x11%V;\\xb4\\xc9-\\xe6\\xe22\\xacFVS\\xb4\\xf8\\x0f\\xfc\\x03\\xfb\\xe9\\xfc\\xda\\xcf\\x8b\\xa7\\xf3\\x9c\\xe7\\xfb\\x9c\\xe7<\\xe7\\x9c\\x0f}}}UUU\\x99\\x99\\x99\\x13\\x13\\x13\\xbf\\x84\\xc1\\xc1\\xc1\\x81\\x81\\x01\\xab\\xd5Z[[\\xdb\\xd1\\xd11<<<99\\x89svvvhh(\\'\\'\\x87\\xb5\\xa5\\xa5\\x05Ayyyjj\\xea\\xd4\\xd4\\xd4\\xd8\\xd8XSS\\xd3g\\xa1\\xa6\\xa6&666##cuuudd\\x84mLLLzzzii\\xa9\\xd9l\\x8e\\x8f\\x8fg\\x1b\\x17\\x17\\x97\\x9f\\x9f___\\xdf\\xd0\\xd0\\xa0\\xd7\\xeb\\x13\\x13\\x13\\x89C&_\\x85\\xd7\\xd7\\xd7\\x9d\\x9d\\x1d<\\x1a\\x8d\\x86\\xc4\\xf0766\\x16\\x17\\x17WWW\\xf3\\nA\\n\\x0b\\x0b\\x8dFc@@@ZZ\\x1a\\x19\\x96\\x95\\x95\\x15\\x15\\x15\\x99L&\\x04&\\x81\\xbb:\\x9d.00\\x90[\\xcd\\xcd\\xcd\\xac<\\xd4\\xd6\\xd6\\x96\\x94\\x94\\xa4\\xd5j\\xf1GEE\\x91|^^\\x1eY\\x11\\x81SBEGG\\x07\\x07\\x07\\xeb\\x84\\x8a\\x8a\\n\\xa2\\xb5\\xb7\\xb7\\'\\'\\'\\xfb\\xfb\\xfb\\xf3\"aI\\x83\\xca\\xf4\\xf4\\xf4\\xb0%\\xff\\xdc\\xdc\\xdc\\x94\\x94\\x14\\x8d\\xc0\\x17\\xb8B&_\\xfe\\x83\\x804\\xb2\\xb2\\xb2\\x10[,\\x16\\x8a\\xcc\\x8b\\x95\\x95\\x95\\x14\\x84_\\xf0M4\\x04\\'\\x19\\xfe\\xc8C\\x9cR\\xea\\x85\\x85\\x85\\xefBBB\\x02\\xf9\\xf0\\xe2\\xf4\\xf4\\xf4\\xde\\xde\\x9e\\xddng\\x9d\\x9f\\x9f\\xdf\\xda\\xdaZZZ\\xfa( \\xa0\\xc2\\x8b\\x8b\\x8b\\x1cy<\\x9e\\xab\\xab\\xab\\x95\\x95\\x15\\xfa\\xf8M\\x18\\x1f\\x1f\\xa7q\\xca\\xa9\\xdb\\xed\\xe6\\x8f\\x88\\x1f\\x1f\\x1f\\xbd^\\xef_\\xe1\\xf9\\xf9\\xf9\\xe5\\xe5\\x85+\\xa7\\xa7\\xa7OOO\\xca\\xd1\\x1f\\xc1#\\xf0\\xe8\\xd1\\xd1\\x91\\xd3\\xe9<>>v\\xb9\\\\\\x17\\x17\\x17l\\x7f\\n\\xe7\\xe7\\xe76\\x9bmccc{{{}}}mm\\x8d\\xdc677\\xf1\\x9f\\x9c\\x9c\\xec\\xef\\xef\\xdb\\x84\\xc3\\xc3\\xc3\\xb3\\xb33\\xae\\xe3<88\\xc0\\x8f\\x9e|\\x88\\xb3\\xbb\\xbb\\xab\\xdc\\x9a\\x99\\x99\\xe1G\\xd8\\xcb\\xcb\\xcbsss\\x8c\\x13\\x99\\x8f\\x8e\\x8e\\xfe\\x10\\xa8Lggg\\x7f\\x7f\\x7foo\\xafU\\xc0S+\\xd08\\x9aKa\\x95fQ\\xab\\xba\\xba:&\\x93F\\xe3\\xe7T\\xd1wuuuwwcX\\x04F\\x94\\xa3\\xd6\\xd6V\\x94\\xd4\\xc4,(cC\\x0bJJJh\\x9c\\xc1`(((0\\x08z\\xc1(`dgg\\x7f\\x12\\xe8\\xac2\\x03L;c\\xa3\\x15\\xe8\\xa6Z\\xadf`T*\\x15\\x86J\\xc0\\xa9\\x08\\x82\\x82\\x82\\xc2\\xc3\\xc3####\"\"\\xd8\\x86\\x85\\x85\\x85\\x86\\x86\\xd2G\\x94\\xbe\\xbe\\xbe~~~\\xd8\\xf8\\x19l\\xae\\x84\\x84\\x84\\xa0W\\x0bJ\\x04<\\x18\\x04G\\x80\\xd8\\xc7\\xc7\\x87\\x08\\xf4\\xee\\xfd\\xfd\\x9d\\x96\\xdd\\xdf\\xdf\\xdf\\xde\\xde\\xde\\xdd\\xdda\\xb0b\\xbf\\xbd\\xbd=<<\\xfc\\x16\\xae\\xaf\\xaf\\xe9\\xa0\\xc3\\xe1\\xa0\\xa7\\xcc\\x89C\\xb8\\xbc\\xbct\\nn\\x01\\x81]\\xe0\\x88^\\xb3\\xbd\\xb9\\xb9A\\xach\\x10\\xe3\\xc7 \\x14\\xc1]\\x02\\x02\\x82\\xb3z\\x85\\x7f\\x90\\x03\\xeb\\x8f\\xa1o\\xa5\\xd0\\x00\\x00\\x00\\x00IEND\\xaeB`\\x82',\n",
       " 'mask': None,\n",
       " 'page': 2,\n",
       " 'caption': ''}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "page_2_strips[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd66cb8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import io\n",
    "\n",
    "def is_horizontal_strip(img):\n",
    "    return img[\"height\"] <2 and img[\"width\"] > 40\n",
    "\n",
    "def get_stripped_images(images):\n",
    "    stripped_images = []\n",
    "    strips = [img for img in images if is_horizontal_strip(img)]\n",
    "    x0s = np.unique([strip[\"bbox\"][0] for strip in page_2_strips])\n",
    "    if len(x0s) > 1:\n",
    "        raise ValueError(\n",
    "                f\"Multiple stripped images detected on the page (x0s={x0s}). \"\n",
    "                \"Refactor required to handle multiple horizontal strips.\"\n",
    "            )\n",
    "    return strips\n",
    "\n",
    "def stitch_strips(image_blocks, output_path=\"stitched_image.png\"):\n",
    "    \"\"\"\n",
    "    Stitch a list of horizontal image strips (already sorted top-to-bottom) into a single image.\n",
    "    \"\"\"\n",
    "    images = [Image.open(io.BytesIO(block[\"image\"])) for block in image_blocks ]\n",
    "\n",
    "    total_height = sum(img.height for img in images)\n",
    "    max_width = max(img.width for img in images)\n",
    "\n",
    "    stitched = Image.new(\"RGB\", (max_width, total_height), (255, 255, 255))\n",
    "    offset = 0\n",
    "    for img in images:\n",
    "        stitched.paste(img, (0, offset))\n",
    "        offset += img.height\n",
    "\n",
    "    stitched.save(output_path)\n",
    "\n",
    "stitch_strips(page_2_strips)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ogham",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d4d39df",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import pandas as pd\n",
    "import numpy  as np\n",
    "from numpy.linalg import norm\n",
    "import fitz\n",
    "from fitz import Rect\n",
    "import re\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "from sklearn.pipeline import make_pipeline, Pipeline\n",
    "from sklearn.compose  import ColumnTransformer, make_column_selector, make_column_transformer\n",
    "\n",
    "from pdf_scraper.block_utils import get_block_text, print_block_table, clean_blocks\n",
    "from pdf_scraper.doc_utils import open_exam\n",
    "from pdf_scraper.line_utils import line_is_empty, print_line_table, get_line_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e2997c8",
   "metadata": {},
   "source": [
    "Below we see that on page 4 of 2024, the 7th block has a subtitle and dual column text blocked together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2036dff",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc              = open_exam(2024)\n",
    "page             = doc[3]\n",
    "page_dict        = page.get_text(\"dict\",sort=True)\n",
    "blocks           = page_dict[\"blocks\"]\n",
    "block            = blocks[6]\n",
    "lines            = block['lines']\n",
    "lines = [line for line in lines if not line_is_empty(line)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdb145dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(get_block_text(block))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "769cdd69",
   "metadata": {},
   "outputs": [],
   "source": [
    "print_line_table(lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "720e91e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option(\"display.float_format\", \"{:.2f}\".format)\n",
    "df = get_line_df(lines)\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f018203d",
   "metadata": {},
   "source": [
    "# Preprocessing dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ca5acc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#bad_nums = [\"n_spans\",\"dL\",\"x1\",\"n_words\",\"h\",\"x0\",\"y1\"]\n",
    "#bad_cats = [\"font_list\",\"text\",\"mode_font\"]\n",
    "bad_nums = [\"n_spans\",\"dL\",\"x0\",\"n_words\",\"x1\",\"h\"]\n",
    "bad_cats = [\"font_list\",\"text\", \"font_sizes\",\"category\" ]\n",
    "\n",
    "num_vars = [ col for col in df.select_dtypes(include=np.number).columns if col not in bad_nums ] \n",
    "cat_vars = [ col for col in df.select_dtypes(include='object').columns  if col not in bad_cats ] \n",
    "X_cols   = num_vars + cat_vars\n",
    "\n",
    "\n",
    "ohe = OneHotEncoder(drop=\"if_binary\", sparse_output=False, handle_unknown=\"error\" )\n",
    "\n",
    "basic_preproc = make_column_transformer(\n",
    "    (StandardScaler(), num_vars),\n",
    "    (OneHotEncoder(drop=\"if_binary\",sparse_output=False, handle_unknown=\"error\"), cat_vars),\n",
    "    remainder=\"drop\"\n",
    "    )\n",
    "basic_kmeans = make_pipeline(basic_preproc, KMeans(n_clusters=2,  n_init=400))\n",
    "\n",
    "X    = basic_preproc.fit_transform(df)\n",
    "X_df = pd.DataFrame(X, columns=X_cols)\n",
    "\n",
    "display(X_df.head(4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee17da08",
   "metadata": {},
   "source": [
    "# Clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb59b9ef",
   "metadata": {},
   "source": [
    "## Default Kmeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21d34b07",
   "metadata": {},
   "outputs": [],
   "source": [
    "display_df = df.copy()\n",
    "display_df[\"cluster\"] = basic_kmeans.fit_predict(df)\n",
    "display_df.head(7)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d973dea2",
   "metadata": {},
   "source": [
    "We see the default Kmeans fails with these features, the one word line \"Elaine.\" is associated with the wrong block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f02c4b7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_init    = X[0]\n",
    "bottom_init = X[-1]  \n",
    "init_centroids = [ top_init, bottom_init ]\n",
    "\n",
    "kmeans = KMeans(n_clusters=2, random_state=42,init=init_centroids, n_init=\"auto\")\n",
    "y_pred = kmeans.fit_predict(X)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe64bffc",
   "metadata": {},
   "source": [
    "## Weighted Kmeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86eefbb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_weighted = X_df.copy()\n",
    "\n",
    "y_weight    = math.sqrt(2)\n",
    "font_weight = math.sqrt(4)\n",
    "\n",
    "X_weighted[[\"y0\",\"y1\"]]                 = X_df[[\"y0\",\"y1\"]]*y_weight\n",
    "X_weighted[[\"common_font\",\"mode_font\"]] = X_df[[\"common_font\",\"mode_font\"]]*font_weight \n",
    "X_weighted.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9adfb4ac",
   "metadata": {},
   "source": [
    "### Manual centroid initialisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f5a6f1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "init_centroids = [ X[0], X[-1] ]\n",
    "kmeans = KMeans(n_clusters=2, random_state=42,init=init_centroids, n_init=\"auto\",verbose=True)\n",
    "cluster_pred = kmeans.fit_predict(X_weighted)\n",
    "pd.concat((X_weighted,pd.Series(cluster_pred,name=\"Cluster\") ),axis=1).head(7)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e040977",
   "metadata": {},
   "source": [
    "### 1000 random centroids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a08006f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans = KMeans(n_clusters=2, n_init=1000)\n",
    "cluster_pred = kmeans.fit_predict(X_weighted)\n",
    "print(kmeans.inertia_)\n",
    "pd.concat((X_weighted,pd.Series(cluster_pred,name=\"Cluster\") ),axis=1).head(18)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7083457e",
   "metadata": {},
   "source": [
    "# Full custom K-means"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d92c275",
   "metadata": {},
   "source": [
    "## Pre proc X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ce6f99f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = basic_preproc.fit_transform(df)\n",
    "X_df = pd.DataFrame(basic_preproc.fit_transform(df),columns=X_cols)\n",
    "X_df.head(6)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dd371de",
   "metadata": {},
   "source": [
    "## Initialise clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9149c55f",
   "metadata": {},
   "outputs": [],
   "source": [
    "clusts = X[[0, X.shape[0]-1]]\n",
    "clust0, clust1 = clusts\n",
    "clusts.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38dc1d88",
   "metadata": {},
   "source": [
    "## Calculate cluster distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcdfac53",
   "metadata": {},
   "outputs": [],
   "source": [
    "dist0 = (clust0-X[0]).T@(clust0-X[0])\n",
    "dist1 = (clust1-X[0]).T@(clust1-X[0])\n",
    "print(np.sqrt(dist0),np.sqrt(dist1))\n",
    "dists = [norm( clust - X[0]) for clust in clusts]\n",
    "print(dists[0],dists[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "238cbf3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dist0 = norm(X-clusts[0],axis=1)\n",
    "dist1 = norm(X-clusts[1],axis=1)\n",
    "dists = np.vstack((dist0, dist1)).T\n",
    "print(X.shape)\n",
    "print(clusts.shape)\n",
    "print(dists.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab1cb3db",
   "metadata": {},
   "source": [
    "### Fully vectorised"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "988a4cb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "diff  = X[:, np.newaxis, :] - clusts[np.newaxis, :, :]  #  (17, 2, 8)\n",
    "dists = norm(diff, axis=2)  #  (17, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a9c0ed1",
   "metadata": {},
   "source": [
    "### Examine distance components for edge point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c31ffd29",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"{'i':<5} {'clust':<5} {'l':<8} {'dy0':8} {'dw':8} {'dfont':8}\")\n",
    "for i, x in enumerate(X):\n",
    "    for j, clust in enumerate(clusts):\n",
    "        l = norm(x - clust)\n",
    "        dr = (x - clust)**2\n",
    "        dw    = dr[2]\n",
    "        dy0   = dr[0]\n",
    "        dfont = dr[3]\n",
    "        if i == 3:  \n",
    "            print(f\"{i:<5} {j:<5} {l:<8.2f} {dy0:<8.2f} {dw:<8.2f} {dfont:<8.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a027bd95",
   "metadata": {},
   "outputs": [],
   "source": [
    "dists[3]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4afe71e1",
   "metadata": {},
   "source": [
    "## Label data points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66a71733",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_bool = dists[:,0]> dists[:,1] # If it is closer to 0 the label is 0. So we want dists[:,0]< dists[:,1] to give 0\n",
    "y = np.array( y_bool ,dtype= np.int64 )\n",
    "\n",
    "print(\"Cluster 0\\nShape:\",X[y_bool].shape)\n",
    "print(\"Cluster 1\\nShape:\",X[~y_bool].shape)\n",
    "\n",
    "X_df_labelled = pd.concat((X_df,pd.Series(y,name=\"cluster\")), axis=1) \n",
    "X_df_labelled.head(6)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81b04d0b",
   "metadata": {},
   "source": [
    "### Fully vectorised"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99b07edd",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = np.argmin(dists, axis=1)  # shape (17,) \n",
    "k = clusts.shape[0]  # number of clusters (e.g. 2)\n",
    "\n",
    "# Use list comprehension to compute new means per cluster label\n",
    "new_clusts = np.vstack([X[labels == i].mean(axis=0) for i in range(k)])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0346d89",
   "metadata": {},
   "source": [
    "## Recalculate cluster centres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0163150d",
   "metadata": {},
   "outputs": [],
   "source": [
    "clust0 = np.mean(X[y_bool], axis=0)\n",
    "clust1 = np.mean(X[~y_bool], axis=0 )\n",
    "new_clusts = np.vstack( (clust0,clust1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f7fee1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X.shape)\n",
    "print(new_clusts.shape)\n",
    "dist0 = np.linalg.norm(X-new_clusts[0],axis=1)\n",
    "dist1 = np.linalg.norm(X-new_clusts[1],axis=1)\n",
    "\n",
    "dists = np.vstack((dist0, dist1)).T\n",
    "dists.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "070ebb2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X[:, np.newaxis, :].shape)\n",
    "print(clusts[np.newaxis, :, :].shape)\n",
    "diff = X[:, np.newaxis, :] - clusts[np.newaxis, :, :]  #  (17, 2, 8)\n",
    "dists = np.linalg.norm(diff, axis=2)  #  (17, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfc60584",
   "metadata": {},
   "source": [
    "## Check cluster displacement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33cdd876",
   "metadata": {},
   "outputs": [],
   "source": [
    "dclust = new_clusts - clusts\n",
    "print(dclust.shape)\n",
    "clust_delta = norm(dclust, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef9de352",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X.shape)\n",
    "i_nword = X.shape[1]-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27e260a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_vect = X[:,:i_nword]\n",
    "full_vect.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b423c3e7",
   "metadata": {},
   "source": [
    "## One Iteration Custom Cluster"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ccc3e28",
   "metadata": {},
   "source": [
    "### Define dataframe and word mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab89389b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df        = get_line_df(lines)\n",
    "\n",
    "# We need to choose now the rows where the number of words is below 4\n",
    "word_mask = df[\"n_words\"].to_numpy() < 4\n",
    "\n",
    "print(\"Raw lines dataframe:\")\n",
    "display(df.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5a44b25",
   "metadata": {},
   "source": [
    "## Preprocess data frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b1a2c64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# These cols of the df are not informative for text-block clustering.\n",
    "bad_nums = [\"n_spans\",\"dL\",\"x1\",\"n_words\",\"x0\",\"h\",\"y1\"]\n",
    "bad_cats = [\"font_list\",\"text\", \"mode_font\", \"font_sizes\",\"category\"]\n",
    "\n",
    "num_vars = [ col for col in  df.select_dtypes(include=np.number).columns if col not in bad_nums] \n",
    "cat_vars = [ col for col in  df.select_dtypes(include='object').columns  if col not in bad_cats] \n",
    "\n",
    "basic_preproc = make_column_transformer(\n",
    "    (StandardScaler(), num_vars),\n",
    "    (OneHotEncoder(drop=\"if_binary\",sparse_output=False, handle_unknown=\"error\"), cat_vars),\n",
    "    remainder=\"drop\"\n",
    "    )\n",
    "X_cols = num_vars + cat_vars \n",
    "X      = basic_preproc.fit_transform(df)\n",
    "X_df   = pd.DataFrame(X,columns=X_cols )\n",
    "print(f\"Preprocessed dataframe of shape {X.shape}:\")\n",
    "print(X_df.head(8),\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c79487e7",
   "metadata": {},
   "source": [
    "## Initialise clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16a367b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialise clusters - first and last data point are top and bottom of page\n",
    "k=2\n",
    "m, n = X.shape\n",
    "clusts  = X[[0, m-1]]\n",
    "d_clust = norm(clusts,axis=1)\n",
    "inertia = d_clust.T@d_clust\n",
    "i_w       = X_cols.index(\"w\")\n",
    "print(clusts.shape)\n",
    "print(d_clust , inertia)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ce3b5bb",
   "metadata": {},
   "source": [
    "## Normal distance calc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf1289f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# full distance calc for certain, N-1 dimensional for others.\n",
    "full_vect  = X[~word_mask, :]\n",
    "full_clust = clusts[:, :]\n",
    "\n",
    "full_diff   = full_vect[:, np.newaxis, :] - full_clust[np.newaxis, :, :]  #  (m_full, 2, n)\n",
    "full_dists  = norm(full_diff, axis=2)                                     #  (m_full, 2)\n",
    "\n",
    "print(f\"Full vector of shape {full_vect.shape}\")\n",
    "#print(pd.DataFrame(full_vect, columns= X_cols).head(8),\"\\n\\n\" )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eda32bc7",
   "metadata": {},
   "source": [
    "## Distance for few-word lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbc064b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If we have a line with a small n_words, the width is no longer a good variable for clustering.\n",
    "small_vect  = np.delete(X[word_mask], i_w, axis=1)\n",
    "small_clust = np.delete(clusts,       i_w, axis=1)\n",
    "\n",
    "small_diff   = small_vect[:, np.newaxis, :] - small_clust[np.newaxis, :, :]  #  (m_small, 2, n -1)\n",
    "small_dists  = norm(small_diff, axis=2)                                      #  (m_small, 2)\n",
    "\n",
    "small_cols = [i for i in X_cols if i != \"w\" ]\n",
    "\n",
    "print(f\"Width-excluded vector of shape {small_vect.shape}\")\n",
    "print(pd.DataFrame(small_vect, columns = small_cols).head(2),\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03b4047d",
   "metadata": {},
   "source": [
    "## Combine distances  - label points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f48df2d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine distances and label \n",
    "dists = np.empty((m, k))\n",
    "dists[word_mask]  = small_dists\n",
    "dists[~word_mask] = full_dists\n",
    "labels = np.argmin(dists, axis=1)\n",
    "\n",
    "X_df[\"cluster\"] = pd.Series(labels)\n",
    "X_df.head(8)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5788534d",
   "metadata": {},
   "source": [
    "## Calculate new clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc730211",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_clusts = np.vstack([X[labels == i].mean(axis=0) for i in range(k)])\n",
    "\n",
    "norm_change =  norm(clusts-new_clusts,axis=1)\n",
    "norm_clust  =  norm(clusts,axis = 1)\n",
    "\n",
    "tol = 0.01\n",
    "if all(norm_change/norm_clust < tol):\n",
    "    print(\"clust has barely moved\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7cc23cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_variable_diffs(X, clusts, X_cols, word_mask, i_w):\n",
    "    \"\"\"\n",
    "    Computes squared variable-wise differences between each point and clusters.\n",
    "    Returns a DataFrame with columns like d0_w, d1_w, d0_y0, etc.\n",
    "    \"\"\"\n",
    "    m, n = X.shape\n",
    "    k = clusts.shape[0]\n",
    "\n",
    "    full_vect = X[~word_mask]\n",
    "    full_diffs = (full_vect[:, np.newaxis, :] - clusts[np.newaxis, :, :]) ** 2\n",
    "\n",
    "    small_vect  = np.delete(X[word_mask], i_w, axis=1)\n",
    "    small_clust = np.delete(clusts, i_w, axis=1)\n",
    "    small_diffs = (small_vect[:, np.newaxis, :] - small_clust[np.newaxis, :, :]) ** 2\n",
    "\n",
    "    all_diffs = np.empty((m, k, n))\n",
    "    all_diffs[~word_mask] = full_diffs\n",
    "    # Fill small_diffs into all_diffs for word_mask rows (with width excluded)\n",
    "    # We must check below tomorrow pretty sure they are the same.\n",
    "    all_diffs[word_mask, :, :i_w]   = small_diffs[:, :, :i_w]\n",
    "    all_diffs[word_mask, :, i_w+1:] = small_diffs[:, :, i_w:]\n",
    "    all_diffs[word_mask, :, i_w]    = 0  \n",
    "\n",
    "\n",
    "    var_dfs = []\n",
    "    for cluster_i in range(k):\n",
    "        cluster_diff = all_diffs[:, cluster_i, :]\n",
    "        cluster_df = pd.DataFrame(cluster_diff, columns=[f\"d{cluster_i}_{col}\" for col in X_cols])\n",
    "        var_dfs.append(cluster_df)\n",
    "\n",
    "    return pd.concat(var_dfs, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd5cae7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "m, n = X.shape\n",
    "k = clusts.shape[0]\n",
    "\n",
    "full_vect = X[~word_mask]\n",
    "full_diffs = (full_vect[:, np.newaxis, :] - clusts[np.newaxis, :, :]) ** 2\n",
    "\n",
    "small_vect  = np.delete(X[word_mask], i_w, axis=1)\n",
    "small_clust = np.delete(clusts, i_w, axis=1)\n",
    "small_diffs = (small_vect[:, np.newaxis, :] - small_clust[np.newaxis, :, :]) ** 2\n",
    "\n",
    "all_diffs = np.empty((m, k, n))\n",
    "all_diffs[~word_mask] = full_diffs\n",
    "# Fill small_diffs into all_diffs for word_mask rows (with width excluded)\n",
    "# We must check below tomorrow pretty sure they are the same.\n",
    "all_diffs[word_mask, :, :i_w]   = small_diffs[:, :, :i_w]\n",
    "all_diffs[word_mask, :, i_w+1:] = small_diffs[:, :, i_w:]\n",
    "all_diffs[word_mask, :, i_w]    = 0  \n",
    "all_diffs[word_mask]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36c28fc6",
   "metadata": {},
   "source": [
    "# Test custom Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baf88494",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pdf_scraper.clustering.customCluster import reblock_lines\n",
    "doc              = open_exam(2024)\n",
    "page             = doc[1]\n",
    "page_dict        = page.get_text(\"dict\",sort=True)\n",
    "blocks           = page_dict[\"blocks\"]\n",
    "blocks           = clean_blocks(blocks)\n",
    "print_block_table(blocks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34908b65",
   "metadata": {},
   "outputs": [],
   "source": [
    "block            = blocks[1]\n",
    "lines            = [line for line in block[\"lines\"] if not line_is_empty(line)]\n",
    "print(get_block_text(block))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5fe8f1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "line_lables = reblock_lines(lines)\n",
    "# from above we can see that first line should be one block, next two should be next\n",
    "expected    = np.array([0,1,1])\n",
    "assert (reblock_lines(lines) == expected).all()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ogham",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

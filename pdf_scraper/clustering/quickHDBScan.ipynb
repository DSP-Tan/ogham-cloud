{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4777337",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d1e7d56",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import fitz\n",
    "from fitz import Rect\n",
    "from PIL import Image\n",
    "import sys, re\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.metrics import pairwise_distances\n",
    "\n",
    "from pdf_scraper.doc_utils   import open_exam, get_doc_line_df, identify_section_headers, identify_text_headers, get_path_from_doc\n",
    "from pdf_scraper.doc_utils   import identify_footers, identify_instructions, identify_subtitles, identify_subsubtitles\n",
    "from pdf_scraper.line_utils  import clean_line_df, get_df_bbox\n",
    "from pdf_scraper.doc_utils   import get_images, filter_images, get_raw_lines, assign_in_image_captions, identify_vertical_captions\n",
    "from pdf_scraper.clustering.cluster_utils import find_y0_dL\n",
    "from pdf_scraper.image_utils import show_image, show_all_imgs\n",
    "\n",
    "pd.set_option(\"display.float_format\", \"{:.2f}\".format)\n",
    "pd.set_option(\"display.max_colwidth\", 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e8abdde",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get cluster bboxes\n",
    "def get_cluster_boxes(df, labels):\n",
    "    rectangies = []\n",
    "    clust_labes = np.unique(labels)[1:] if -1 in labels else np.unique(labels)\n",
    "    for i in clust_labes:\n",
    "        temp_df = df[df.cluster==i]\n",
    "        rectangies.append( Rect(get_df_bbox(temp_df)) )\n",
    "    return rectangies\n",
    "\n",
    "def get_category_boxes(df, cat):\n",
    "    rectangies = []\n",
    "    clust_labes = np.unique(df[cat])[1:] if -1 in df[cat] else np.unique(df[cat])\n",
    "    for i in clust_labes:\n",
    "        temp_df = df[df[cat]==i]\n",
    "        rectangies.append( Rect(get_df_bbox(temp_df)) )\n",
    "    return rectangies\n",
    "\n",
    "def enrich_doc_df_with_images(df, images):\n",
    "    poo = {val: [ img[\"bbox\"][i] for img in images ] for i, val in enumerate([\"x0\",\"y0\",\"x1\",\"y1\"])}\n",
    "    img_dict = { }\n",
    "    for i, coord in enumerate([\"x0\",\"y0\",\"x1\",\"y1\"]):\n",
    "        img_dict[coord]   = [ img[\"bbox\"][i] for img in images ]\n",
    "    img_dict[\"page\"]  = [ img[\"page\"]   for img in images]\n",
    "    img_dict[\"image\"] = [1]*len(images)\n",
    "    img_df = pd.DataFrame(img_dict)    \n",
    "    rich_df = pd.concat([df, img_df],ignore_index=True).sort_values(by=[\"page\",\"y0\"],ignore_index=True)\n",
    "    \n",
    "    return rich_df\n",
    "\n",
    "def get_bboxed_page_image(doc,  page_number: int, rects: list[Rect],  color: tuple[float]=(0,0,0.0), labels: list[int] = [], ) -> Image:\n",
    "    i_p  = int(page_number-1)\n",
    "\n",
    "    out_doc = fitz.open()\n",
    "    out_doc.insert_pdf(doc, from_page=i_p, to_page=i_p)\n",
    "    page = out_doc[0]\n",
    "\n",
    "    for i, rect in enumerate(rects):\n",
    "        page.draw_rect(rect, color=color, width=3)\n",
    "        if len(labels) >0:\n",
    "            label_text = str(labels[i])\n",
    "            pos = fitz.Point(rect.x0, rect.y0 - 2)  # adjust -2 for spacing\n",
    "            page.insert_text(pos, label_text, fontsize=8, color=(1,0,0))\n",
    "\n",
    "    pix = page.get_pixmap(matrix=fitz.Matrix(1, 1))  # scale=2 for higher resolution\n",
    "    img = Image.frombytes(\"RGB\", [pix.width, pix.height], pix.samples)\n",
    "\n",
    "    out_doc.close()\n",
    "\n",
    "    return img\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4007fc96",
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_bbox_next_row_dist(y0, y1, y0_next, y1_next):\n",
    "    \"\"\"End-to-end vertical distance between two line segments.\n",
    "\n",
    "    This function will return 0 if the two bboxes overlap in the chosen dimension.\n",
    "    Otherwise it will return the distance between their closest endpoints.\n",
    "    \"\"\"\n",
    "    overlap = np.maximum(y0, y0_next) <= np.minimum(y1, y1_next)\n",
    "    dist = np.where(overlap, 0.0, np.minimum(np.abs(y1 - y0_next), np.abs(y1_next - y0)))\n",
    "    return dist\n",
    "\n",
    "def df_bbox_dist(row1, row2):\n",
    "    \"\"\"\n",
    "    This calculates the bbox end to end distance between to dataframe rows.\n",
    "\n",
    "    It can be used to generate a distance matrix between all rows of a dataframe of lines.\n",
    "    \n",
    "    df_bbox_dist(row1[[\"y0\",\"y1]], row2[[\"y0\",\"y1\"]]) = vertical   end to end bbox distance\n",
    "    df_bbox_dist(row1[[\"x0\",\"x1]], row2[[\"x0\",\"x1\"]]) = horizontal end to end bbox distance\n",
    "    \"\"\"\n",
    "    y0, y1 = row1\n",
    "    y0_next, y1_next = row2\n",
    "\n",
    "    overlap = max(y0, y0_next) <= min(y1, y1_next)\n",
    "    if overlap:\n",
    "        return 0.0\n",
    "    return min(abs(y1 - y0_next), abs(y1_next - y0))\n",
    "\n",
    "\n",
    "\n",
    "def split_cluster(df: pd.DataFrame, i_clust: int,  metric, eps, dir, verbose=False):\n",
    "    if verbose: print(f\"scanning cluster {i_clust}\")\n",
    "    last_id  = df.cluster.max()\n",
    "    clust_df = df[df.cluster==i_clust].copy()\n",
    "\n",
    "    X             = pairwise_distances(clust_df[dir],metric=metric)\n",
    "    scan          = DBSCAN(eps=eps, min_samples=1,metric=\"precomputed\")\n",
    "    labels        = scan.fit_predict(X)\n",
    "    \n",
    "    unique_labels = np.unique(labels)\n",
    "    n_labels = len( unique_labels )\n",
    "    if n_labels ==1:\n",
    "        if verbose: print(\"No split\")\n",
    "        return  unique_labels\n",
    "    \n",
    "    labels[labels!=0] += last_id\n",
    "    labels[labels==0] += i_clust\n",
    "\n",
    "    df.loc[clust_df.index, \"cluster\"] = labels\n",
    "    unique_labels = np.unique(labels)\n",
    "    \n",
    "    if verbose: print(f\"Cluster {i_clust} split {dir} with eps = {round(eps)} into {n_labels} clusters: {unique_labels}\")\n",
    "\n",
    "    return unique_labels\n",
    "\n",
    "def hdbscan(df: pd.DataFrame, max_iter: int, eps_x: float, eps_y: float, metric, verbose=False):\n",
    "    dir1 = [\"y0\"] if metric==\"euclidean\" else [\"y0\",\"y1\"]\n",
    "    dir2 = [\"x0\"] if metric==\"euclidean\" else [\"x0\",\"x1\"]\n",
    "    dirs = ((dir1, eps_y), (dir2,eps_x))\n",
    "    i_dir, n_fail, df[\"cluster\"] = (0, 0, 0)\n",
    "    N_clusters=1\n",
    "    rectangies, labia = ([], [])\n",
    "    \n",
    "    for n_loop in range(max_iter):\n",
    "        # assign the direction and cluster numbers for this round of scanning\n",
    "        dir, eps  = dirs[i_dir]\n",
    "    \n",
    "        if verbose: print(f\"Full Scan {n_loop} in {dir} with eps={eps:<6.0f}\")\n",
    "        if n_fail >=4:\n",
    "            break\n",
    "        # Loop over all current clusters and break up in dir\n",
    "        for i_clust in np.unique(df.cluster):\n",
    "            split_cluster(df, i_clust, metric, eps, dir, verbose=verbose)\n",
    "                \n",
    "        labelos = np.unique(df.cluster)\n",
    "        n_clusters = len(labelos)\n",
    "        i_dir = 1 if i_dir==0 else 0\n",
    "    \n",
    "        if n_clusters == N_clusters:\n",
    "            n_fail +=1\n",
    "            continue\n",
    "        else:\n",
    "            n_fail = 0\n",
    "            N_clusters = n_clusters\n",
    "    \n",
    "        rectangies.append(get_category_boxes(df, 'cluster') )\n",
    "        labia.append( np.unique(df.cluster) )\n",
    "        if verbose: print(f\"Total {n_clusters} clusters: {labelos}\")\n",
    "\n",
    "    return ( rectangies, labia )\n",
    "\n",
    "#rectangs, labia = hdbscan(page_df, 100, eps_x0, eps_y0, \"euclidean\",False)\n",
    "#imgs = [get_bboxed_page_image(doc, page, rectangies,color=(0.0,0,0.0), labels=labelos) for rectangies, labelos in zip(rectangs, labia)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a06ae83e",
   "metadata": {},
   "outputs": [],
   "source": [
    "year=2019\n",
    "#year=2002\n",
    "doc    = open_exam(year, \"english\", \"al\",1)\n",
    "df     = get_doc_line_df(doc)\n",
    "\n",
    "images = get_images(doc)\n",
    "images = filter_images(images)\n",
    "assign_in_image_captions(df,images)\n",
    "\n",
    "doc_width     = doc[0].rect.width\n",
    "middle        = doc_width/2\n",
    "standard_font = df.mode_font.mode()[0]\n",
    "median_font   = df.font_size.median()\n",
    "\n",
    "\n",
    "df = clean_line_df(df)\n",
    "identify_footers(df)\n",
    "identify_instructions(df)\n",
    "identify_section_headers(df)\n",
    "identify_text_headers(df, doc_width)\n",
    "identify_subtitles(df, doc_width)\n",
    "identify_subsubtitles(df,doc_width)\n",
    "\n",
    "\n",
    "for image in images:\n",
    "    if image[\"page\"] <2 or image[\"page\"] >8:\n",
    "        continue\n",
    "    identify_vertical_captions(df, image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "519c2d04",
   "metadata": {},
   "outputs": [],
   "source": [
    "page = np.unique(df[df.caption2==1].page)[0]\n",
    "page_df = df.loc[df.page==page, [\"text\", 'x0', 'y0', 'x1', 'y1', \"page\",\"w\"]].copy()\n",
    "page_images = [image for image in images if image[\"page\"]==page]\n",
    "page_df = enrich_doc_df_with_images(page_df,page_images)\n",
    "page_df[\"dL\"] = page_df.y0.diff()\n",
    "\n",
    "doc_page = doc[int(page-1)]\n",
    "pix = doc_page.get_pixmap(matrix=fitz.Matrix(0.8, 0.5))  # scale=2 for higher resolution\n",
    "img = Image.frombytes(\"RGB\", [pix.width, pix.height], pix.samples)\n",
    "print(f\"page: {page}\")\n",
    "display(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6b6c256",
   "metadata": {},
   "source": [
    "## Separate y0 and x0 scans "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79afdc42",
   "metadata": {},
   "outputs": [],
   "source": [
    "eps_y0 = dL_y0 = find_y0_dL(page_df)*1.15\n",
    "scan_y = DBSCAN(eps=dL_y0, min_samples=1)\n",
    "page_df[\"y_cluster\"]= scan_y.fit_predict(page_df[[\"y0\"]])\n",
    "\n",
    "\n",
    "median_w = page_df.w.dropna().map(round).median()\n",
    "eps_x0    = median_w*0.5\n",
    "scan_x = DBSCAN(eps=eps_x0, min_samples=1)\n",
    "page_df[\"x_cluster\"]= scan_x.fit_predict(page_df[[\"x0\"]])\n",
    "\n",
    "rectangies_y = get_category_boxes(page_df, 'y_cluster')\n",
    "y_img = get_bboxed_page_image(doc, page, rectangies_y, color=(0,0,0.5), labels=np.unique(page_df.y_cluster) )\n",
    "\n",
    "\n",
    "rectangies_x = get_category_boxes(page_df, 'x_cluster')\n",
    "x_img = get_bboxed_page_image(doc, page, rectangies_x,color=(0.5,0,0.0),labels = np.unique(scan_x.labels_))\n",
    "\n",
    "# Join lcluster labels\n",
    "page_df[\"xy_cluster\"] = page_df.groupby([\"x_cluster\", \"y_cluster\"]).ngroup()\n",
    "rectangies_xy = get_category_boxes(page_df, 'xy_cluster')\n",
    "xy_img = get_bboxed_page_image(doc, page, rectangies_xy,color=(0.0,0,0.0),labels=np.unique(page_df.xy_cluster))\n",
    "\n",
    "fig, axes = plt.subplots(1,3,figsize=(16,8))\n",
    "\n",
    "axes[0].imshow(y_img); axes[0].axis(\"off\"); axes[0].set_title(\"y0-scan\");\n",
    "axes[1].imshow(x_img); axes[1].axis(\"off\"); axes[1].set_title(\"x0-scan\")\n",
    "axes[2].imshow(xy_img); axes[2].axis(\"off\"); axes[2].set_title(\"x0y0-scan\")\n",
    "plt.subplots_adjust(wspace=0.0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1ab8568",
   "metadata": {},
   "source": [
    "- This is an improved clustering. But we notice that not all pagraphs are separated in y\n",
    "  - Do another y clustering within each group.\n",
    "  - The issue is that, when looking only at y, the existence of \"A library in the middle\" to the right of the paragraph ending in \"Eames lamp\" gives a false\n",
    "    impression of contiguity."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10a02585",
   "metadata": {},
   "source": [
    "# Hierarchical alternating scan till stability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "063eaf11",
   "metadata": {},
   "outputs": [],
   "source": [
    "median_dy0 = find_y0_dL(page_df)\n",
    "median_w   = page_df.w.median()\n",
    "eps_y0     = median_dy0*1.15\n",
    "eps_x0     = median_w*0.5\n",
    "\n",
    "rectangs, labia = hdbscan(page_df, 100, eps_x0, eps_y0, \"euclidean\",False)\n",
    "imgs = [get_bboxed_page_image(doc, page, rectangies,color=(0.0,0,0.0), labels=labelos) for rectangies, labelos in zip(rectangs, labia)]\n",
    "display(imgs[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6e7dc11",
   "metadata": {},
   "source": [
    "# Scan using bbox distances"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "067a9958",
   "metadata": {},
   "source": [
    "# Loop over years"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d3a2589",
   "metadata": {},
   "outputs": [],
   "source": [
    "year=2001; page = 2 \n",
    "def check_year_page(year, page, x_scale, y_scale):\n",
    "    doc    = open_exam(year, \"english\", \"al\",1)\n",
    "    df     = get_doc_line_df(doc)\n",
    "    \n",
    "    images = get_images(doc)\n",
    "    images = filter_images(images)\n",
    "    assign_in_image_captions(df,images)\n",
    "    \n",
    "    df = clean_line_df(df)\n",
    "    for image in images:\n",
    "        if image[\"page\"] <2 or image[\"page\"] >8:\n",
    "            continue\n",
    "        identify_vertical_captions(df, image)\n",
    "    page_images = [image for image in images if image[\"page\"]==page]\n",
    "    \n",
    "    page_df = df.loc[df.page==page, [\"text\", 'x0', 'y0', 'x1', 'y1', \"page\",\"w\"]].copy()\n",
    "    page_df = enrich_doc_df_with_images(page_df,page_images)\n",
    "    \n",
    "    \n",
    "    page_df[\"dL_e2e\"] = df_bbox_next_row_dist(page_df.y0, page_df.y1, page_df.y0.shift(-1), page_df.y1.shift(-1) )\n",
    "    dLs = page_df.dL_e2e.dropna()\n",
    "    dL_median = dLs[dLs!=0].median()\n",
    "    \n",
    "    #y_scale = 1.00\n",
    "    eps_y = dL_median * y_scale\n",
    "    \n",
    "    middle = (page_df.x0.min() + page_df.x1.max())/2\n",
    "    left  = page_df[page_df.x1 < middle +5 ]\n",
    "    right = page_df[page_df.x0 > middle -5 ]\n",
    "    \n",
    "    left_right_dist  = pairwise_distances(left[[\"x0\",\"x1\"]], right[[\"x0\",\"x1\"]], metric=df_bbox_dist)\n",
    "    eps_x = x_scale * left_right_dist.min()\n",
    "    # This is for the case were there is document length lines on the same page as the dual columns.\n",
    "    # These will cause the min end to end difference to be 0. 10 is a good estimate for an appropriate x distance\n",
    "    # found by trial and error.\n",
    "    eps_x = 10 if eps_x == 0 else eps_x   \n",
    "    \n",
    "    \n",
    "    print(f\"eps_x: {eps_x} eps_y: {eps_y}\")\n",
    "    \n",
    "    rectangs, labia = hdbscan(page_df, 100, eps_x, eps_y, df_bbox_dist,False)\n",
    "    imgs = [get_bboxed_page_image(doc, page, rectangies,color=(0.0,0,0.0), labels=labelos) for rectangies, labelos in zip(rectangs, labia)]\n",
    "    display(imgs[-1])\n",
    "#check_year_page(2023, 6, (2.0/3.0), 1.10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fb015cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "for year, page in [(2001, 2),(2002, 6),(2010, 7),(2011, 2),(2011, 3),(2012, 4),(2012, 5),\n",
    "                   (2013, 4),(2013, 6),(2013, 7),(2014, 3),(2023, 6),(2024, 3)]:\n",
    "    print(year, page)\n",
    "    check_year_page(year, page, 2/3, 1.1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ogham",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4777337",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d1e7d56",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import fitz\n",
    "from fitz import Rect\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.metrics import pairwise_distances\n",
    "\n",
    "from pdf_scraper.doc_utils     import open_exam, get_doc_line_df, identify_section_headers, identify_text_headers, get_path_from_doc\n",
    "from pdf_scraper.doc_utils     import identify_footers, identify_instructions, identify_subtitles, identify_subsubtitles\n",
    "from pdf_scraper.line_utils    import clean_line_df, get_category_boxes, get_df_bbox\n",
    "from pdf_scraper.doc_utils     import get_images, filter_images, assign_in_image_captions, identify_vertical_captions\n",
    "from pdf_scraper.doc_utils     import enrich_doc_df_with_images\n",
    "from pdf_scraper.clustering.cluster_utils import find_y0_dL, split_cluster, hdbscan\n",
    "from pdf_scraper.general_utils import df_bbox_dist, df_bbox_next_row_dist\n",
    "from pdf_scraper.image_utils   import get_bboxed_page_image\n",
    "\n",
    "pd.set_option(\"display.float_format\", \"{:.2f}\".format)\n",
    "pd.set_option(\"display.max_colwidth\", 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a06ae83e",
   "metadata": {},
   "outputs": [],
   "source": [
    "year=2019\n",
    "doc    = open_exam(year, \"english\", \"al\",1)\n",
    "df     = get_doc_line_df(doc)\n",
    "\n",
    "images = get_images(doc)\n",
    "images = filter_images(images)\n",
    "assign_in_image_captions(df,images)\n",
    "\n",
    "doc_width     = doc[0].rect.width\n",
    "middle        = doc_width/2\n",
    "standard_font = df.mode_font.mode()[0]\n",
    "median_font   = df.font_size.median()\n",
    "\n",
    "\n",
    "df = clean_line_df(df)\n",
    "identify_footers(df)\n",
    "identify_instructions(df)\n",
    "identify_section_headers(df)\n",
    "identify_text_headers(df, doc_width)\n",
    "identify_subtitles(df, doc_width)\n",
    "identify_subsubtitles(df,doc_width)\n",
    "\n",
    "\n",
    "for image in images:\n",
    "    if image[\"page\"] <2 or image[\"page\"] >8:\n",
    "        continue\n",
    "    identify_vertical_captions(df, image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "519c2d04",
   "metadata": {},
   "outputs": [],
   "source": [
    "page = np.unique(df[df.caption2==1].page)[0]\n",
    "page_df = df.loc[df.page==page, [\"text\", 'x0', 'y0', 'x1', 'y1', \"page\",\"w\"]].copy()\n",
    "page_images = [image for image in images if image[\"page\"]==page]\n",
    "page_df = enrich_doc_df_with_images(page_df,page_images)\n",
    "page_df[\"dL\"] = page_df.y0.diff()\n",
    "\n",
    "doc_page = doc[int(page-1)]\n",
    "pix = doc_page.get_pixmap(matrix=fitz.Matrix(0.8, 0.5))  # scale=2 for higher resolution\n",
    "img = Image.frombytes(\"RGB\", [pix.width, pix.height], pix.samples)\n",
    "print(f\"page: {page}\")\n",
    "display(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6b6c256",
   "metadata": {},
   "source": [
    "## Separate y0 and x0 scans "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79afdc42",
   "metadata": {},
   "outputs": [],
   "source": [
    "eps_y0 = dL_y0 = find_y0_dL(page_df)*1.15\n",
    "scan_y = DBSCAN(eps=dL_y0, min_samples=1)\n",
    "page_df[\"y_cluster\"]= scan_y.fit_predict(page_df[[\"y0\"]])\n",
    "\n",
    "\n",
    "median_w = page_df.w.dropna().map(round).median()\n",
    "eps_x0    = median_w*0.5\n",
    "scan_x = DBSCAN(eps=eps_x0, min_samples=1)\n",
    "page_df[\"x_cluster\"]= scan_x.fit_predict(page_df[[\"x0\"]])\n",
    "\n",
    "rectangies_y = get_category_boxes(page_df, 'y_cluster')\n",
    "y_img = get_bboxed_page_image(doc, page, rectangies_y, color=(0,0,0.5), labels=np.unique(page_df.y_cluster) )\n",
    "\n",
    "\n",
    "rectangies_x = get_category_boxes(page_df, 'x_cluster')\n",
    "x_img = get_bboxed_page_image(doc, page, rectangies_x,color=(0.5,0,0.0),labels = np.unique(scan_x.labels_))\n",
    "\n",
    "# Join lcluster labels\n",
    "page_df[\"xy_cluster\"] = page_df.groupby([\"x_cluster\", \"y_cluster\"]).ngroup()\n",
    "rectangies_xy = get_category_boxes(page_df, 'xy_cluster')\n",
    "xy_img = get_bboxed_page_image(doc, page, rectangies_xy,color=(0.0,0,0.0),labels=np.unique(page_df.xy_cluster))\n",
    "\n",
    "fig, axes = plt.subplots(1,3,figsize=(16,8))\n",
    "\n",
    "axes[0].imshow(y_img); axes[0].axis(\"off\"); axes[0].set_title(\"y0-scan\");\n",
    "axes[1].imshow(x_img); axes[1].axis(\"off\"); axes[1].set_title(\"x0-scan\")\n",
    "axes[2].imshow(xy_img); axes[2].axis(\"off\"); axes[2].set_title(\"x0y0-scan\")\n",
    "plt.subplots_adjust(wspace=0.0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1ab8568",
   "metadata": {},
   "source": [
    "- This is an improved clustering. But we notice that not all pagraphs are separated in y\n",
    "  - Do another y clustering within each group.\n",
    "  - The issue is that, when looking only at y, the existence of \"A library in the middle\" to the right of the paragraph ending in \"Eames lamp\" gives a false\n",
    "    impression of contiguity."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10a02585",
   "metadata": {},
   "source": [
    "# Hierarchical alternating scan till stability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "063eaf11",
   "metadata": {},
   "outputs": [],
   "source": [
    "median_dy0 = find_y0_dL(page_df)\n",
    "median_w   = page_df.w.median()\n",
    "eps_y0     = median_dy0*1.15\n",
    "eps_x0     = median_w*0.5\n",
    "\n",
    "rectangs, labia = hdbscan(page_df, 100, eps_x0, eps_y0, \"euclidean\",False)\n",
    "imgs = [get_bboxed_page_image(doc, page, rectangies,color=(0.0,0,0.0), labels=labelos) for rectangies, labelos in zip(rectangs, labia)]\n",
    "display(imgs[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6e7dc11",
   "metadata": {},
   "source": [
    "# Scan using bbox distances"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "067a9958",
   "metadata": {},
   "source": [
    "# Loop over years"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d3a2589",
   "metadata": {},
   "outputs": [],
   "source": [
    "year=2001; page = 2 \n",
    "def check_year_page(year, page, x_scale, y_scale):\n",
    "    doc    = open_exam(year, \"english\", \"al\",1)\n",
    "    df     = get_doc_line_df(doc)\n",
    "    \n",
    "    images = get_images(doc)\n",
    "    images = filter_images(images)\n",
    "    assign_in_image_captions(df,images)\n",
    "    \n",
    "    df = clean_line_df(df)\n",
    "    for image in images:\n",
    "        if image[\"page\"] <2 or image[\"page\"] >8:\n",
    "            continue\n",
    "        identify_vertical_captions(df, image)\n",
    "    page_images = [image for image in images if image[\"page\"]==page]\n",
    "    \n",
    "    page_df = df.loc[df.page==page, [\"text\", 'x0', 'y0', 'x1', 'y1', \"page\",\"w\"]].copy()\n",
    "    page_df = enrich_doc_df_with_images(page_df,page_images)\n",
    "    \n",
    "    \n",
    "    page_df[\"dL_e2e\"] = df_bbox_next_row_dist(page_df.y0, page_df.y1, page_df.y0.shift(-1), page_df.y1.shift(-1) )\n",
    "    dLs = page_df.dL_e2e.dropna()\n",
    "    dL_median = dLs[dLs!=0].median()\n",
    "    \n",
    "    eps_y = dL_median * y_scale\n",
    "    \n",
    "    middle = (page_df.x0.min() + page_df.x1.max())/2\n",
    "    left  = page_df[page_df.x1 < middle +5 ]\n",
    "    right = page_df[page_df.x0 > middle -5 ]\n",
    "    \n",
    "    left_right_dist  = pairwise_distances(left[[\"x0\",\"x1\"]], right[[\"x0\",\"x1\"]], metric=df_bbox_dist)\n",
    "    mask = (left_right_dist!=0)                 # Exclude overlapping lines\n",
    "    eps_x = x_scale * left_right_dist[mask].min()\n",
    "\n",
    "    # This is for the case were there is document length lines on the same page as the dual columns.\n",
    "    # These will cause the min end to end difference to be 0. 10 is a good estimate for an appropriate x distance\n",
    "    # found by trial and error.\n",
    "    #eps_x = 10 if eps_x == 0 else eps_x   \n",
    "    \n",
    "    \n",
    "    print(f\"eps_x: {eps_x} eps_y: {eps_y}\")\n",
    "    \n",
    "    rectangs, labia = hdbscan(page_df, 100, eps_x, eps_y, df_bbox_dist,False)\n",
    "    imgs = [get_bboxed_page_image(doc, page, rectangies,color=(0.0,0,0.0), labels=labelos) for rectangies, labelos in zip(rectangs, labia)]\n",
    "    display(imgs[-1])\n",
    "#check_year_page(2023, 6, (2.0/3.0), 1.10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fb015cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "for year, page in [(2001, 2),(2002, 6),(2010, 7),(2011, 2),(2011, 3),(2012, 4),(2012, 5),\n",
    "                   (2013, 4),(2013, 6),(2013, 7),(2014, 3),(2023, 6),(2024, 3)]:\n",
    "    print(year, page)\n",
    "    check_year_page(year, page, 2/3, 1.1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ogham",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

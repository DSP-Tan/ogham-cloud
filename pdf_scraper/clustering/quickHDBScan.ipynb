{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "90d06c1e",
   "metadata": {},
   "source": [
    "This notebook will do more or less the same as the hdbscan notebook, but here we will only use the final decided upon methods\n",
    "and present no investigations of other methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4777337",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d1e7d56",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import fitz\n",
    "from fitz import Rect\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.metrics import pairwise_distances\n",
    "\n",
    "from pdf_scraper.doc_utils     import open_exam, get_doc_line_df, identify_section_headers, identify_text_headers, get_path_from_doc\n",
    "from pdf_scraper.doc_utils     import identify_footers, identify_instructions, identify_subtitles, identify_subsubtitles\n",
    "from pdf_scraper.line_utils    import clean_line_df, get_category_boxes, get_df_bbox\n",
    "from pdf_scraper.doc_utils     import get_images, filter_images, assign_in_image_captions, identify_vertical_captions\n",
    "from pdf_scraper.doc_utils     import enrich_doc_df_with_images\n",
    "from pdf_scraper.clustering.cluster_utils import get_vert_neigh_dist, split_cluster, hdbscan, find_y0_dL, correct_eps_y_scale\n",
    "from pdf_scraper.general_utils import df_bbox_dist, df_bbox_next_row_dist\n",
    "from pdf_scraper.image_utils   import get_bboxed_page_image\n",
    "\n",
    "pd.set_option(\"display.float_format\", \"{:.2f}\".format)\n",
    "pd.set_option(\"display.max_colwidth\", 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a06ae83e",
   "metadata": {},
   "outputs": [],
   "source": [
    "year=2019\n",
    "doc    = open_exam(year, \"english\", \"al\",1)\n",
    "df     = get_doc_line_df(doc)\n",
    "\n",
    "images = get_images(doc)\n",
    "images = filter_images(images)\n",
    "assign_in_image_captions(df,images)\n",
    "\n",
    "doc_width     = doc[0].rect.width\n",
    "middle        = doc_width/2\n",
    "standard_font = df.mode_font.mode()[0]\n",
    "median_font   = df.font_size.median()\n",
    "\n",
    "\n",
    "df = clean_line_df(df)\n",
    "identify_footers(df)\n",
    "identify_instructions(df)\n",
    "identify_section_headers(df)\n",
    "identify_text_headers(df, doc_width)\n",
    "identify_subtitles(df, doc_width)\n",
    "identify_subsubtitles(df,doc_width)\n",
    "\n",
    "\n",
    "for image in images:\n",
    "    if image[\"page\"] <2 or image[\"page\"] >8:\n",
    "        continue\n",
    "    identify_vertical_captions(df, image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "519c2d04",
   "metadata": {},
   "outputs": [],
   "source": [
    "page = np.unique(df[df.category==\"caption2\"].page)[0]\n",
    "page_df = df.loc[df.page==page, [\"text\", 'x0', 'y0', 'x1', 'y1', \"page\",\"w\"]].copy()\n",
    "page_images = [image for image in images if image[\"page\"]==page]\n",
    "page_df = enrich_doc_df_with_images(page_df,page_images)\n",
    "#page_df[\"dL\"] = page_df.y0.diff()\n",
    "\n",
    "doc_page = doc[int(page-1)]\n",
    "pix = doc_page.get_pixmap(matrix=fitz.Matrix(0.8, 0.5))  # scale=2 for higher resolution\n",
    "img = Image.frombytes(\"RGB\", [pix.width, pix.height], pix.samples)\n",
    "print(f\"page: {page}\")\n",
    "display(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6b6c256",
   "metadata": {},
   "source": [
    "## Separate y0 and x0 scans "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79afdc42",
   "metadata": {},
   "outputs": [],
   "source": [
    "dL_y0  = page_df.apply(lambda row: get_vert_neigh_dist(row, page_df, [\"y0\"] ), axis=1 ).median()\n",
    "eps_y0 = dL_y0 * 1.15\n",
    "scan_y = DBSCAN(eps=eps_y0, min_samples=1)\n",
    "page_df[\"y_cluster\"]= scan_y.fit_predict(page_df[[\"y0\"]])\n",
    "\n",
    "\n",
    "median_w = page_df.w.dropna().median()\n",
    "eps_x0    = median_w*0.5\n",
    "scan_x = DBSCAN(eps=eps_x0, min_samples=1)\n",
    "page_df[\"x_cluster\"]= scan_x.fit_predict(page_df[[\"x0\"]])\n",
    "\n",
    "rectangies_y = get_category_boxes(page_df, 'y_cluster')\n",
    "y_img = get_bboxed_page_image(doc, page, rectangies_y, color=(0,0,0.5), labels=np.unique(page_df.y_cluster) )\n",
    "\n",
    "\n",
    "rectangies_x = get_category_boxes(page_df, 'x_cluster')\n",
    "x_img = get_bboxed_page_image(doc, page, rectangies_x,color=(0.5,0,0.0),labels = np.unique(scan_x.labels_))\n",
    "\n",
    "# Join lcluster labels\n",
    "page_df[\"xy_cluster\"] = page_df.groupby([\"x_cluster\", \"y_cluster\"]).ngroup()\n",
    "rectangies_xy = get_category_boxes(page_df, 'xy_cluster')\n",
    "xy_img = get_bboxed_page_image(doc, page, rectangies_xy,color=(0.0,0,0.0),labels=np.unique(page_df.xy_cluster))\n",
    "\n",
    "fig, axes = plt.subplots(1,3,figsize=(16,8))\n",
    "\n",
    "axes[0].imshow(y_img); axes[0].axis(\"off\"); axes[0].set_title(f\"y0-scan: eps_y0={eps_y0:<6.2f}\");\n",
    "axes[1].imshow(x_img); axes[1].axis(\"off\"); axes[1].set_title(f\"x0-scan: eps_x0={eps_x0:6.2f}\")\n",
    "axes[2].imshow(xy_img); axes[2].axis(\"off\"); axes[2].set_title(\"x0y0-scan\")\n",
    "plt.subplots_adjust(wspace=0.0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1ab8568",
   "metadata": {},
   "source": [
    "- This is an improved clustering. But we notice that not all pagraphs are separated in y\n",
    "  - Do another y clustering within each group.\n",
    "  - The issue is that, when looking only at y, the existence of \"A library in the middle\" to the right of the paragraph ending in \"Eames lamp\" gives a false\n",
    "    impression of contiguity."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10a02585",
   "metadata": {},
   "source": [
    "# Hierarchical alternating y0-x0 scan till stability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "063eaf11",
   "metadata": {},
   "outputs": [],
   "source": [
    "median_dy0  = page_df.apply(lambda row: get_vert_neigh_dist(row, page_df, [\"y0\"]),axis=1).median()\n",
    "median_w   = page_df.w.median()\n",
    "eps_y0     = median_dy0*1.15\n",
    "eps_x0     = median_w*0.5\n",
    "\n",
    "rectangs, labia = hdbscan(page_df, 100, eps_x0, eps_y0, \"euclidean\",False)\n",
    "imgs = [get_bboxed_page_image(doc, page, rectangies,color=(0.0,0,0.0), labels=labelos) for rectangies, labelos in zip(rectangs, labia)]\n",
    "display(imgs[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6e7dc11",
   "metadata": {},
   "source": [
    "# Scan using bbox distances"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "067a9958",
   "metadata": {},
   "source": [
    "# Loop over years"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d3a2589",
   "metadata": {},
   "outputs": [],
   "source": [
    "year=2001; page = 2 \n",
    "def check_year_page(year, page, x_scale, y_scale):\n",
    "    doc    = open_exam(year, \"english\", \"al\",1)\n",
    "    df     = get_doc_line_df(doc)\n",
    "    \n",
    "    images = get_images(doc)\n",
    "    images = filter_images(images)\n",
    "    assign_in_image_captions(df,images)\n",
    "    \n",
    "    df = clean_line_df(df)\n",
    "    for image in images:\n",
    "        if image[\"page\"] <2 or image[\"page\"] >8:\n",
    "            continue\n",
    "        identify_vertical_captions(df, image)\n",
    "    page_images = [image for image in images if image[\"page\"]==page]\n",
    "    \n",
    "    page_df = df.loc[df.page==page, [\"text\", 'x0', 'y0', 'x1', 'y1', \"page\",\"w\"]].copy()\n",
    "    page_df = enrich_doc_df_with_images(page_df,page_images)\n",
    "    \n",
    "    dL_median = page_df.apply(lambda row: get_vert_neigh_dist(row, page_df, [\"y0\",\"y1\"]),axis=1 ).median()\n",
    "\n",
    "    y_scale = correct_eps_y_scale(page_df, page, y_scale)\n",
    "    eps_y = dL_median * y_scale\n",
    "    \n",
    "    middle = (page_df.x0.min() + page_df.x1.max())/2\n",
    "    left  = page_df[page_df.x1 < middle +5 ]\n",
    "    right = page_df[page_df.x0 > middle -5 ]\n",
    "    \n",
    "    left_right_dist  = pairwise_distances(left[[\"x0\",\"x1\"]], right[[\"x0\",\"x1\"]], metric=df_bbox_dist)\n",
    "    mask = (left_right_dist!=0)                 # Exclude overlapping lines\n",
    "    eps_x = x_scale * left_right_dist[mask].min()\n",
    "    \n",
    "    print(f\"eps_x: {eps_x:<8.2f} eps_y: {eps_y:<8.2f} eps_y scale:{y_scale:4.2f}\")\n",
    "    \n",
    "    rectangs, labia = hdbscan(page_df, 100, eps_x, eps_y, df_bbox_dist,False)\n",
    "    imgs = [get_bboxed_page_image(doc, page, rectangies,color=(0.0,0,0.0), labels=labelos) for rectangies, labelos in zip(rectangs, labia)]\n",
    "    display(imgs[-1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fb015cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# These are years where there are captions outside of images. We would like to use hdbscan to differentiate \n",
    "# these caption lines from other lines.\n",
    "for year, page in [(2001, 2),(2002, 6),(2010, 7),(2011, 2),(2011, 3),(2012, 4),(2012, 5),\n",
    "                   (2013, 4),(2013, 6),(2013, 7),(2014, 3),(2019,2) ,(2023, 6),(2024, 3)]:\n",
    "    print(year, page)\n",
    "    check_year_page(year, page, 2/3, 1.15)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ogham",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

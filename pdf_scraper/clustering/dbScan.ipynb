{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4777337",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d1e7d56",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import fitz\n",
    "from fitz import Rect\n",
    "from PIL import Image\n",
    "from time import sleep\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.metrics import pairwise_distances\n",
    "\n",
    "from pdf_scraper.doc_utils   import open_exam, get_doc_line_df, identify_section_headers, identify_text_headers\n",
    "from pdf_scraper.doc_utils   import identify_footers, identify_instructions, identify_subtitles, identify_subsubtitles\n",
    "from pdf_scraper.line_utils  import clean_line_df, get_df_bbox\n",
    "from pdf_scraper.doc_utils   import get_images, filter_images,  assign_in_image_captions, identify_vertical_captions\n",
    "from pdf_scraper.clustering.cluster_utils import find_y0_dL\n",
    "from pdf_scraper.image_utils import show_image, show_all_imgs\n",
    "\n",
    "pd.set_option(\"display.float_format\", \"{:.2f}\".format)\n",
    "pd.set_option(\"display.max_colwidth\", 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e8abdde",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_category_boxes(df, cat):\n",
    "    rectangies = []\n",
    "    clust_labes = np.unique(df[cat])[1:] if -1 in df[cat] else np.unique(df[cat])\n",
    "    for i in clust_labes:\n",
    "        temp_df = df[df[cat]==i]\n",
    "        rectangies.append( Rect(get_df_bbox(temp_df)) )\n",
    "    return rectangies\n",
    "\n",
    "def enrich_doc_df_with_images(df, images):\n",
    "    poo = {val: [ img[\"bbox\"][i] for img in images ] for i, val in enumerate([\"x0\",\"y0\",\"x1\",\"y1\"])}\n",
    "    img_dict = { }\n",
    "    for i, coord in enumerate([\"x0\",\"y0\",\"x1\",\"y1\"]):\n",
    "        img_dict[coord]   = [ img[\"bbox\"][i] for img in images ]\n",
    "    img_dict[\"page\"]  = [ img[\"page\"]   for img in images]\n",
    "    img_dict[\"image\"] = [1]*len(images)\n",
    "    img_df = pd.DataFrame(img_dict)    \n",
    "    rich_df = pd.concat([df, img_df],ignore_index=True).sort_values(by=[\"page\",\"y0\"],ignore_index=True)\n",
    "    \n",
    "    return rich_df\n",
    "\n",
    "def get_bboxed_page_image(doc,  page_number: int, rects: list[Rect],  color: tuple[float]=(0,0,0.0), labels: list[int] = [], ) -> Image:\n",
    "    i_p  = int(page_number-1)\n",
    "\n",
    "    out_doc = fitz.open()\n",
    "    out_doc.insert_pdf(doc, from_page=i_p, to_page=i_p)\n",
    "    page = out_doc[0]\n",
    "\n",
    "    for i, rect in enumerate(rects):\n",
    "        page.draw_rect(rect, color=color, width=3)\n",
    "        if len(labels) >0:\n",
    "            label_text = str(labels[i])\n",
    "            pos = fitz.Point(rect.x0, rect.y0 - 2)  # adjust -2 for spacing\n",
    "            page.insert_text(pos, label_text, fontsize=8, color=(1,0,0))\n",
    "\n",
    "    pix = page.get_pixmap(matrix=fitz.Matrix(1, 1))  # scale=2 for higher resolution\n",
    "    img = Image.frombytes(\"RGB\", [pix.width, pix.height], pix.samples)\n",
    "\n",
    "    out_doc.close()\n",
    "\n",
    "    return img\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4007fc96",
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_bbox_next_row_dist(y0, y1, y0_next, y1_next):\n",
    "    \"\"\"End-to-end vertical distance between two line segments.\n",
    "\n",
    "    This function will return 0 if the two bboxes overlap in the chosen dimension.\n",
    "    Otherwise it will return the distance between their closest endpoints.\n",
    "    \"\"\"\n",
    "    overlap = np.maximum(y0, y0_next) <= np.minimum(y1, y1_next)\n",
    "    dist = np.where(overlap, 0.0, np.minimum(np.abs(y1 - y0_next), np.abs(y1_next - y0)))\n",
    "    return dist\n",
    "\n",
    "def df_bbox_dist(row1, row2):\n",
    "    \"\"\"\n",
    "    This calculates the bbox end to end distance between to dataframe rows.\n",
    "\n",
    "    It can be used to generate a distance matrix between all rows of a dataframe of lines.\n",
    "    \n",
    "    df_bbox_dist(row1[[\"y0\",\"y1]], row2[[\"y0\",\"y1\"]]) = vertical   end to end bbox distance\n",
    "    df_bbox_dist(row1[[\"x0\",\"x1]], row2[[\"x0\",\"x1\"]]) = horizontal end to end bbox distance\n",
    "    \"\"\"\n",
    "    y0, y1 = row1\n",
    "    y0_next, y1_next = row2\n",
    "\n",
    "    overlap = max(y0, y0_next) <= min(y1, y1_next)\n",
    "    if overlap:\n",
    "        return 0.0\n",
    "    return min(abs(y1 - y0_next), abs(y1_next - y0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0410bf37",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_cluster(df: pd.DataFrame, i_clust: int,  metric, eps, dir, verbose=False):\n",
    "    if verbose: print(f\"scanning cluster {i_clust}\")\n",
    "    last_id  = df.cluster.max()\n",
    "    clust_df = df[df.cluster==i_clust].copy()\n",
    "\n",
    "    X             = pairwise_distances(clust_df[dir],metric=metric)\n",
    "    scan          = DBSCAN(eps=eps, min_samples=1,metric=\"precomputed\")\n",
    "    labels        = scan.fit_predict(X)\n",
    "    \n",
    "    unique_labels = np.unique(labels)\n",
    "    n_labels = len( unique_labels )\n",
    "    if n_labels ==1:\n",
    "        if verbose: print(\"No split\")\n",
    "        return  unique_labels\n",
    "    \n",
    "    labels[labels!=0] += last_id\n",
    "    labels[labels==0] += i_clust\n",
    "\n",
    "    df.loc[clust_df.index, \"cluster\"] = labels\n",
    "    unique_labels = np.unique(labels)\n",
    "    \n",
    "    if verbose: print(f\"Cluster {i_clust} split {dir} with eps = {round(eps)} into {n_labels} clusters: {unique_labels}\")\n",
    "\n",
    "    return unique_labels\n",
    "\n",
    "def hdbscan(df: pd.DataFrame, max_iter: int, eps_x: float, eps_y: float, metric, verbose=False):\n",
    "    dir1 = [\"y0\"] if metric==\"euclidean\" else [\"y0\",\"y1\"]\n",
    "    dir2 = [\"x0\"] if metric==\"euclidean\" else [\"x0\",\"x1\"]\n",
    "    dirs = ((dir1, eps_y), (dir2,eps_x))\n",
    "    i_dir, n_fail, df[\"cluster\"] = (0, 0, 0)\n",
    "    N_clusters=1\n",
    "    rectangies, labia = ([], [])\n",
    "    \n",
    "    for n_loop in range(max_iter):\n",
    "        # assign the direction and cluster numbers for this round of scanning\n",
    "        dir, eps  = dirs[i_dir]\n",
    "    \n",
    "        print(f\"Full Scan {n_loop} in {dir} with eps={eps:<6.0f}\")\n",
    "        if n_fail >=4:\n",
    "            break\n",
    "        # Loop over all current clusters and break up in dir\n",
    "        for i_clust in np.unique(df.cluster):\n",
    "            split_cluster(df, i_clust, metric, eps, dir, verbose=verbose)\n",
    "                \n",
    "        labelos = np.unique(df.cluster)\n",
    "        n_clusters = len(labelos)\n",
    "        i_dir = 1 if i_dir==0 else 0\n",
    "    \n",
    "        if n_clusters == N_clusters:\n",
    "            n_fail +=1\n",
    "            continue\n",
    "        else:\n",
    "            n_fail = 0\n",
    "            N_clusters = n_clusters\n",
    "    \n",
    "        rectangies.append(get_category_boxes(df, 'cluster') )\n",
    "        labia.append( np.unique(df.cluster) )\n",
    "        print(f\"Total {n_clusters} clusters: {labelos}\")\n",
    "\n",
    "    return ( rectangies, labia )\n",
    "\n",
    "#rectangs, labia = hdbscan(page_df, 100, eps_x0, eps_y0, \"euclidean\",False)\n",
    "#imgs = [get_bboxed_page_image(doc, page, rectangies,color=(0.0,0,0.0), labels=labelos) for rectangies, labelos in zip(rectangs, labia)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a06ae83e",
   "metadata": {},
   "outputs": [],
   "source": [
    "year=2019\n",
    "#year=2002\n",
    "doc    = open_exam(year, \"english\", \"al\",1)\n",
    "df     = get_doc_line_df(doc)\n",
    "\n",
    "images = get_images(doc)\n",
    "images = filter_images(images)\n",
    "assign_in_image_captions(df,images)\n",
    "\n",
    "doc_width     = doc[0].rect.width\n",
    "middle        = doc_width/2\n",
    "standard_font = df.mode_font.mode()[0]\n",
    "median_font   = df.font_size.median()\n",
    "\n",
    "\n",
    "df = clean_line_df(df)\n",
    "identify_footers(df)\n",
    "identify_instructions(df)\n",
    "identify_section_headers(df)\n",
    "identify_text_headers(df, doc_width)\n",
    "identify_subtitles(df, doc_width)\n",
    "identify_subsubtitles(df,doc_width)\n",
    "\n",
    "\n",
    "for image in images:\n",
    "    if image[\"page\"] <2 or image[\"page\"] >8:\n",
    "        continue\n",
    "    identify_vertical_captions(df, image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "519c2d04",
   "metadata": {},
   "outputs": [],
   "source": [
    "page = np.unique(df[df.caption2==1].page)[0]\n",
    "page_df = df.loc[df.page==page, [\"text\", 'x0', 'y0', 'x1', 'y1', \"page\"]].copy()\n",
    "doc_page = doc[int(page-1)]\n",
    "\n",
    "pix = doc_page.get_pixmap(matrix=fitz.Matrix(0.8, 0.5))  # scale=2 for higher resolution\n",
    "img = Image.frombytes(\"RGB\", [pix.width, pix.height], pix.samples)\n",
    "print(f\"page: {page}\")\n",
    "display(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ed4202d",
   "metadata": {},
   "source": [
    "# Enrich doc_df with image information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "040a5ce0",
   "metadata": {},
   "outputs": [],
   "source": [
    "page_df     = df[df.page==page]\n",
    "page_images = [image for image in images if image[\"page\"]==page]\n",
    "show_image(page_images[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "578e900d",
   "metadata": {},
   "outputs": [],
   "source": [
    "page_df = enrich_doc_df_with_images(page_df,page_images)\n",
    "page_df[\"dL\"] = page_df.y0.diff()\n",
    "page_df[['x0', 'y0', 'x1', 'y1', 'mode_font',  'text', 'font_size', 'image', 'page', 'counts']].head(8)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ab5bad7",
   "metadata": {},
   "source": [
    "# Basic dbscan on X0 and Y0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44f324bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1,2,figsize=(16,4))\n",
    "\n",
    "sns.histplot(page_df.y0,ax=axes[0]);\n",
    "sns.histplot(page_df.x0,ax=axes[1]);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6b6c256",
   "metadata": {},
   "source": [
    "## y0 scan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79afdc42",
   "metadata": {},
   "outputs": [],
   "source": [
    "eps_y0 = dL_y0 = find_y0_dL(page_df)*1.15\n",
    "X = pairwise_distances(page_df[[\"y0\"]],metric=\"euclidean\")\n",
    "\n",
    "scan = DBSCAN(eps=eps_y0, min_samples=1, metric=\"precomputed\")\n",
    "page_df[\"y_cluster\"]= scan.fit_predict(X)\n",
    "\n",
    "rectangies = get_category_boxes(page_df, 'y_cluster')\n",
    "y_img = get_bboxed_page_image(doc, page, rectangies,color=(0,0,0.5), labels= np.unique(page_df.y_cluster))\n",
    "display(y_img)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c123fa5d",
   "metadata": {},
   "source": [
    "- Because the closeness is only measured with y0, we can see that cluster 2 contains the image, and the lines down to wolverhampton \n",
    "- The bbox extracted from this goes to the end of the image, but actually only contains the images and the first paragraph."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e055ea8f",
   "metadata": {},
   "source": [
    "## X0 scan\n",
    "\n",
    "For the x0 dbscan, we will base eps on the median line width. <br>\n",
    "If a line is separated from another by more than a column width, it is not in its epsilon neighbourhood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4608817e",
   "metadata": {},
   "outputs": [],
   "source": [
    "median_w = page_df.w.dropna().map(round).median()\n",
    "eps_x0   = median_w*0.5\n",
    "\n",
    "X    = pairwise_distances(page_df[[\"x0\"]],metric=\"euclidean\")\n",
    "scan = DBSCAN(eps=eps_x0, min_samples=1, metric=\"precomputed\")\n",
    "page_df[\"x_cluster\"] = scan.fit_predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87c53f4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "rectangies = get_category_boxes(page_df, 'x_cluster')\n",
    "x_img = get_bboxed_page_image(doc, page, rectangies,color=(0.5,0,0.0),labels = np.unique(scan.labels_))\n",
    "fig, axes = plt.subplots(1,2,figsize=(16,8))\n",
    "\n",
    "axes[0].imshow(y_img); axes[0].axis(\"off\"); axes[0].set_title(\"y0-scan\");\n",
    "axes[1].imshow(x_img); axes[1].axis(\"off\"); axes[1].set_title(\"x0-scan\")\n",
    "plt.subplots_adjust(wspace=0.0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d1e8bc3",
   "metadata": {},
   "source": [
    "- Cluster 0 contains every line that starts within w from the left hand side, including the title and subtitle.\n",
    "  - The box around them then is a box to the end of the title and subtitle.\n",
    "- Cluster 1 is all the lines or images that start more than x from the very left - right column, figure, and caption."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd4fd979",
   "metadata": {},
   "source": [
    "## Non-hierarchical Double scan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4ece0f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "page_df[\"cluster_id\"] = page_df.groupby([\"x_cluster\", \"y_cluster\"]).ngroup()\n",
    "\n",
    "rectangies = get_category_boxes(page_df, 'cluster_id')\n",
    "xy_img = get_bboxed_page_image(doc, page, rectangies,color=(0.0,0,0.0),labels=np.unique(page_df.cluster_id))\n",
    "display(xy_img)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1ab8568",
   "metadata": {},
   "source": [
    "- This is an improved clustering. But we notice that not all pagraphs are separated in y\n",
    "  - Do another y clustering within each group.\n",
    "  - The issue is that, when looking only at y, the existence of \"A library in the middle\" to the right of the paragraph ending in \"Eames lamp\" gives a false\n",
    "    impression of contiguity."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10a02585",
   "metadata": {},
   "source": [
    "# HDBSCAN with x0 and y0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "063eaf11",
   "metadata": {},
   "outputs": [],
   "source": [
    "#median_dy0 = find_y0_dL(page_df)\n",
    "#median_w   = page_df.w.median()\n",
    "#eps_y0     = median_dy0*1.15\n",
    "#eps_x0     = median_w*0.5\n",
    "#\n",
    "#dirs = (([\"y0\"],eps_y0), ([\"x0\"],eps_x0))\n",
    "#i_dir = 0\n",
    "#page_df[\"cluster\"]=0\n",
    "#N_clusters=1\n",
    "#n_fail = 0\n",
    "#\n",
    "#for n_loop in range(60):\n",
    "#    # assign the direction and cluster numbers for this round of scanning\n",
    "#    dir = dirs[i_dir][0] ; eps = dirs[i_dir][1]\n",
    "#    last_id = len(np.unique(page_df.cluster))\n",
    "#\n",
    "#    print(f\"Scan {n_loop} in {dir}\")\n",
    "#    if n_fail >=4:\n",
    "#        break\n",
    "#    # Loop over all current clusters and break up in dir\n",
    "#    for i_clust in np.unique(page_df.cluster):\n",
    "#        #split_cluster(page_df, i_clust, \"euclidean\", eps, dir, True)\n",
    "#\n",
    "#        clust_df = page_df[page_df.cluster==i_clust].copy()\n",
    "#\n",
    "#        scan = DBSCAN(eps=eps, min_samples=1)\n",
    "#        scan.fit(clust_df[[dir]])\n",
    "#\n",
    "#        labels = scan.labels_\n",
    "#        n_labels = len(np.unique(labels) )\n",
    "#\n",
    "#        if n_labels ==1:\n",
    "#            continue\n",
    "#        \n",
    "#        labels[labels==0] = i_clust\n",
    "#        for i in range(1, n_labels):\n",
    "#            labels[labels==i]=last_id\n",
    "#            last_id +=1\n",
    "#        clust_df.cluster = labels\n",
    "#        page_df.loc[clust_df.index, \"cluster\"] = clust_df.cluster\n",
    "#\n",
    "#        print(f\"Cluster {i_clust} split {dir} into {n_labels} clusters: {np.unique(labels)}\")\n",
    "#            \n",
    "#\n",
    "#    labelos = np.unique(page_df.cluster)\n",
    "#    n_clusters = len(labelos)\n",
    "#    i_dir = 1 if i_dir==0 else 0\n",
    "#\n",
    "#    if n_clusters == N_clusters:\n",
    "#        n_fail +=1\n",
    "#        continue\n",
    "#    else:\n",
    "#        n_fail = 0\n",
    "#        N_clusters = n_clusters\n",
    "#\n",
    "#    rectangies = get_category_boxes(page_df, 'cluster')\n",
    "#    img = get_bboxed_page_image(doc, page, rectangies,color=(0.0,0,0.0), labels=labelos)\n",
    "#    print(f\"Total {len(labelos)} clusters: {labelos}\")\n",
    "#    display(img)\n",
    "#    sleep(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7407d0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "median_dy0 = find_y0_dL(page_df)\n",
    "median_w   = page_df.w.median()\n",
    "eps_y0     = median_dy0*1.15\n",
    "eps_x0     = median_w*0.5\n",
    "\n",
    "rectangs, labia = hdbscan(page_df, 100, eps_x0, eps_y0, \"euclidean\",False)\n",
    "imgs = [get_bboxed_page_image(doc, page, rectangies,color=(0.0,0,0.0), labels=labelos) for rectangies, labelos in zip(rectangs, labia)]\n",
    "\n",
    "fig, axes = plt.subplots(1,3,figsize=(16,8))\n",
    "\n",
    "dir=\"y0\"\n",
    "for i in range(len(axes)):\n",
    "    axes[i].imshow(imgs[i]); axes[i].axis(\"off\"); axes[i].set_title(f\"Scan {i+1} in {dir}\");\n",
    "    dir = \"x0\" if dir==\"y0\" else \"y0\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6e7dc11",
   "metadata": {},
   "source": [
    "# Scan using bbox distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2ffd022",
   "metadata": {},
   "outputs": [],
   "source": [
    "dff = page_df[['x0', 'y0', 'x1', 'y1',  'text', 'font_size', 'image', 'counts']].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c040f843",
   "metadata": {},
   "source": [
    "## y-clustering bbox end-to-end "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6075bd2",
   "metadata": {},
   "source": [
    "### find eps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e309f2a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "dff[\"dL\"] = df_bbox_next_row_dist(dff.y0, dff.y1, dff.y0.shift(-1), dff.y1.shift(-1) )\n",
    "dff[\"dy0\"] = dff.y0.shift(-1) - dff.y0\n",
    "dff.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e9cdbc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pdf_scraper.data_sci_utils import examine_value_counts\n",
    "dy0s = dff.dy0.dropna()\n",
    "dy0_median =  dy0s[dy0s !=0].median()\n",
    "dLs = dff.dL.dropna()\n",
    "dL_median = dLs[dLs!=0].median()\n",
    "\n",
    "print(f\"median dy0 {dy0_median:6.2f}                          median dL {dL_median:6.2f}\")\n",
    "examine_value_counts(pd.concat([dy0s.round(1),dLs.round(1)],axis=1),[\"dy0\",\"dL\"])\n",
    "\n",
    "fig, axes = plt.subplots(1,2,figsize=(16,6))\n",
    "sns.histplot(dy0s, ax=axes[0]);\n",
    "sns.histplot(dLs.round(2), ax=axes[1]);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d592c785",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dist_matrix = pairwise_distances(dff[[\"y0\", \"y1\"]].values, metric=df_bbox_dist)\n",
    "mask = ~np.eye(dist_matrix.shape[0], dtype=bool)\n",
    "vals = dist_matrix[mask]  \n",
    "sns.histplot(vals.round(2).flatten());"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d720e2f3",
   "metadata": {},
   "source": [
    "### dbscan Split in y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "935fee40",
   "metadata": {},
   "outputs": [],
   "source": [
    "scan = DBSCAN(eps=dL_median*1.15, min_samples=1,metric=\"precomputed\")\n",
    "X = pairwise_distances(dff[[\"y0\",\"y1\"]],metric=df_bbox_dist)\n",
    "dff[\"y_cluster\"] = scan.fit_predict(X)\n",
    "\n",
    "rectangies = get_category_boxes(dff, 'y_cluster')\n",
    "y_img = get_bboxed_page_image(doc, page, rectangies,color=(0.5,0,0.0))\n",
    "display(y_img)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "135aac7a",
   "metadata": {},
   "source": [
    "- So because we are only considering one direction, the whole dual colum part is counted as one y-block. This is because when there\n",
    "  is a gap in one column, there is text in the next.\n",
    "  - Look for example at the gap after Wolverhampton. This would count as a split if it were not for the fact that too the right we have the image covering this wole distance. So there is a clear connection path of bbox-y-ends from one pagraph to the next."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4dca984",
   "metadata": {},
   "source": [
    "## x-clustering bbox end to end "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "307f6611",
   "metadata": {},
   "source": [
    "### Find epx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55f40b96",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfx = dff.sort_values(by=\"x0\").drop(columns=[\"dL\",\"dy0\"]).copy()\n",
    "\n",
    "dfx[\"dX\"] = df_bbox_next_row_dist(dfx.x0, dfx.x1, dfx.x0.shift(-1), dfx.x1.shift(-1) )\n",
    "dfx[\"dx0\"] = dfx.x0.shift(-1) - dfx.x0\n",
    "\n",
    "dfx.head(6)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3cd0090",
   "metadata": {},
   "source": [
    " - It is not really informative to look at row by row differences in x, this does not reflect normal reading order or document layout.\n",
    "\n",
    " - Let's look at the distributions of the full neighbour distances\n",
    " - Find the characteristic dX to use in the eps scan\n",
    " - do the eps scan\n",
    "\n",
    " - return to hierarchical clustering code.\n",
    "\n",
    " - clean all code and implement on captions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36d8eaec",
   "metadata": {},
   "outputs": [],
   "source": [
    "dist_matrix = pairwise_distances(dfx[[\"x0\", \"x1\"]].values, metric=df_bbox_dist)\n",
    "mask = ~np.eye(dist_matrix.shape[0], dtype=bool)\n",
    "vals = dist_matrix[mask]   \n",
    "\n",
    "dist_matrix2 = pairwise_distances(dfx[[\"x0\"]].values, metric=\"euclidean\")\n",
    "mask2 = ~np.eye(dist_matrix2.shape[0], dtype=bool)\n",
    "vals2 = dist_matrix2[mask2]   \n",
    "\n",
    "fig, axes = plt.subplots(2, 2 , figsize=(16,8))\n",
    "axes = axes.flatten()\n",
    "sns.histplot(vals.round(2).flatten(),ax=axes[0]);\n",
    "axes[0].set_title(\"end to end\");\n",
    "sns.histplot(vals2.round(2).flatten(),ax=axes[1]);\n",
    "axes[1].set_title(\"x0\");\n",
    "\n",
    "sns.histplot(vals[vals!=0].round(2).flatten(),ax=axes[2]);\n",
    "axes[2].set_title(\"end to end - 0 excluded\");\n",
    "sns.histplot(vals2[vals2!=0].round(2).flatten(),ax=axes[3]);\n",
    "axes[3].set_title(\"x0 - 0 excluded\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dacaa31",
   "metadata": {},
   "source": [
    " - e2e has more 0s because now lines which are overlapping over their bboxs are given 0 distance, not just lines which start at the same x0\n",
    " - e2e has outside of 0 a wider spread of values because for many lines with the same x0, there are different x1s. \n",
    "   - Therefore (x0_1 - x1_0) has bigger variety than (x0_1 - x1_0)\n",
    " - for the e2e eps_x, we could use the peak of the 0-excluded distribution on the left.\n",
    "\n",
    " - Let's first see if we can pick out a good candidate by measuring the distance between the dual-column columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb7232d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "x0 = middle-16\n",
    "x1 = middle+9\n",
    "\n",
    "y0 = page_images[0][\"bbox\"][3]\n",
    "y1 = dff.y1.max() -50\n",
    "\n",
    "rectangies = [Rect(x0,y0,x1,y1)]\n",
    "img = get_bboxed_page_image(doc, page, rectangies,color=(0.5,0,0.0))\n",
    "display(img)\n",
    "#plt.imshow(img)\n",
    "\n",
    "eps_x = eps_x_mid_gap =  x1-x0\n",
    "print(f\"Box end to end is {eps_x}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5f5f151",
   "metadata": {},
   "outputs": [],
   "source": [
    "left = dfx[dfx.x1 < middle]\n",
    "right = dfx[dfx.x0 > middle]\n",
    "\n",
    "left_right_dist  = pairwise_distances(left[[\"x0\",\"x1\"]], right[[\"x0\",\"x1\"]], metric=df_bbox_dist)\n",
    "i_leftmost_right = right.x0.argmin()\n",
    "i_rightmost_left = left.x1.argmax()\n",
    "print(f\"{left_right_dist[i_rightmost_left,i_leftmost_right]} should equal {left_right_dist.min()}\")\n",
    "print(f\"Compare to earlier epx_x_mid_gap: {eps_x_mid_gap}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65316e9c",
   "metadata": {},
   "source": [
    "### dbscan split in x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22112086",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1,3, figsize=(16,4))\n",
    "for i, eps_scale in enumerate([0.2, 0.5, 1]):\n",
    "    X = pairwise_distances(dff[[\"x0\",\"x1\"]],metric=df_bbox_dist)\n",
    "    scan = DBSCAN(eps=eps_x*eps_scale, min_samples=1,metric=\"precomputed\")\n",
    "    dff[\"x_cluster\"] = scan.fit_predict(X)\n",
    "    \n",
    "    rectangies = get_category_boxes(dff, 'x_cluster')\n",
    "    x_img = get_bboxed_page_image(doc, page, rectangies,color=(0.5,0,0.0))\n",
    "    axes[i].imshow(x_img); axes[i].axis(\"off\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "284bb682",
   "metadata": {},
   "source": [
    "- This is because the bbox of, for example, the subtitle covers the entire figure, and therefore overlaps in X with every line.\n",
    "  - you need to partition by y first."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8276de4",
   "metadata": {},
   "source": [
    "# HDBSCAN with end-to-end distances"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2860afa",
   "metadata": {},
   "source": [
    "- We are going to do first end-to-end y distance, with end-to-end x\n",
    "- then we will do end-to-end y distance with regular x0\n",
    "- then we will do end-to-end y distance with overlap-and-x0 x."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5362e399",
   "metadata": {},
   "outputs": [],
   "source": [
    "eps_y      = dL_median*1.05\n",
    "eps_x      = 10 #eps_x_mid_gap*0.01\n",
    "\n",
    "# dirs = (([\"y0\",\"y1\"], eps_y), ([\"x0\",\"x1\"],eps_x))\n",
    "# i_dir = 0\n",
    "# page_df[\"cluster\"]=0\n",
    "# N_clusters=1\n",
    "# n_fail = 0\n",
    "# \n",
    "# for n_loop in range(50):\n",
    "#     # assign the direction and cluster numbers for this round of scanning\n",
    "#     dir = dirs[i_dir][0] ; eps = dirs[i_dir][1]\n",
    "#     last_id = len(np.unique(page_df.cluster))\n",
    "# \n",
    "#     print(f\"Full Scan {n_loop} in {dir} with eps={eps:<6.0f}\")\n",
    "#     if n_fail >=4:\n",
    "#         break\n",
    "#     # Loop over all current clusters and break up in dir\n",
    "#     for i_clust in np.unique(page_df.cluster):\n",
    "#         print(f\"scanning cluster {i_clust}\")\n",
    "#         clust_df = page_df[page_df.cluster==i_clust].copy()\n",
    "#         X = pairwise_distances(clust_df[dir],metric=df_bbox_dist)\n",
    "# \n",
    "#         scan = DBSCAN(eps=eps, min_samples=1,metric=\"precomputed\")\n",
    "#         scan.fit(X)\n",
    "# \n",
    "#         labels = scan.labels_\n",
    "#         n_labels = len(np.unique(labels) )\n",
    "# \n",
    "#         if n_labels ==1:\n",
    "#             print(\"No split\")\n",
    "#             continue\n",
    "#         \n",
    "#         print(f\"Cluster {i_clust} split {dir[0][0]} into {n_labels} clusters: {np.unique(labels)}\")\n",
    "#         print(\"Reassigning labels\")\n",
    "#         for i in range(1, n_labels):\n",
    "#             labels[labels==i]=last_id\n",
    "#             last_id +=1\n",
    "#         labels[labels==0] = i_clust\n",
    "#         print(np.unique(labels))\n",
    "#         clust_df.cluster = labels\n",
    "#         page_df.loc[clust_df.index, \"cluster\"] = clust_df.cluster\n",
    "# \n",
    "#         print(f\"Cluster {i_clust} split {dir} into {n_labels} clusters: {np.unique(labels)}\")\n",
    "#             \n",
    "# \n",
    "#     labelos = np.unique(page_df.cluster)\n",
    "#     n_clusters = len(labelos)\n",
    "#     i_dir = 1 if i_dir==0 else 0\n",
    "# \n",
    "#     if n_clusters == N_clusters:\n",
    "#         n_fail +=1\n",
    "#         continue\n",
    "#     else:\n",
    "#         n_fail = 0\n",
    "#         N_clusters = n_clusters\n",
    "# \n",
    "#     rectangies = get_category_boxes(page_df, 'cluster')\n",
    "#     img = get_bboxed_page_image(doc, page, rectangies,color=(0.0,0,0.0), labels=labelos)\n",
    "#     print(f\"Total {len(labelos)} clusters: {labelos}\")\n",
    "#     display(img)\n",
    "#     sleep(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82ee2b37",
   "metadata": {},
   "outputs": [],
   "source": [
    "rectangs, labia = hdbscan(page_df, 100, eps_x, eps_y, df_bbox_dist,False)\n",
    "imgs = [get_bboxed_page_image(doc, page, rectangies,color=(0.0,0,0.0), labels=labelos) for rectangies, labelos in zip(rectangs, labia)]\n",
    "\n",
    "fig, axes = plt.subplots(1,3,figsize=(16,8))\n",
    "\n",
    "dir=\"y0\"\n",
    "for i in range(len(axes)):\n",
    "    axes[i].imshow(imgs[i]); axes[i].axis(\"off\"); axes[i].set_title(f\"{dir}\");\n",
    "    dir = \"x0\" if dir==\"y0\" else \"y0\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc5073ab",
   "metadata": {},
   "source": [
    "## Test split_cluster\n",
    "\n",
    "Here we just manually split the document by looking at the clusters that need splitting after each split.\n",
    "\n",
    "We used mixed metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99c92d3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "page_df.cluster = 0\n",
    "dirs= []\n",
    "last_id = page_df.cluster.max()\n",
    "dir=[\"y0\"]\n",
    "dirs.append(dir)\n",
    "new_clusts = split_cluster(page_df, 0, 'euclidean', eps_y0, dir  )\n",
    "print(np.unique(page_df.cluster))\n",
    "\n",
    "rectangies = get_category_boxes(page_df, 'cluster')\n",
    "img1 = get_bboxed_page_image(doc, page, rectangies,color=(0.0,0,0.0), labels=np.unique(page_df.cluster))\n",
    "\n",
    "dir=[\"x0\",\"x1\"]\n",
    "dirs.append(dir)\n",
    "last_id = split_cluster(page_df, 3,  df_bbox_dist, 10, dir )\n",
    "print(np.unique(page_df.cluster))\n",
    "rectangies = get_category_boxes(page_df, 'cluster')\n",
    "img2 = get_bboxed_page_image(doc, page, rectangies,color=(0.0,0,0.0), labels=np.unique(page_df.cluster))\n",
    "\n",
    "\n",
    "dir=[\"y0\"]\n",
    "dirs.append(dir)\n",
    "last_id = split_cluster(page_df, 5,  \"euclidean\", eps_y0, dir)\n",
    "print(np.unique(page_df.cluster))\n",
    "rectangies = get_category_boxes(page_df, 'cluster')\n",
    "img3 = get_bboxed_page_image(doc, page, rectangies,color=(0.0,0,0.0), labels=np.unique(page_df.cluster))\n",
    "\n",
    "dir=[\"x0\",\"x1\"]\n",
    "dirs.append(dir)\n",
    "last_id = split_cluster(page_df, 2,  df_bbox_dist, 10, [\"x0\",\"x1\"])\n",
    "print(np.unique(page_df.cluster))\n",
    "rectangies = get_category_boxes(page_df, 'cluster')\n",
    "img4 = get_bboxed_page_image(doc, page, rectangies,color=(0.0,0,0.0), labels=np.unique(page_df.cluster))\n",
    "\n",
    "\n",
    "fig, axes = plt.subplots(2,2,figsize=(16,16))\n",
    "imgs = [img1, img2, img3,img4]\n",
    "axes = axes.flatten()\n",
    "\n",
    "for i in range(len(axes)):\n",
    "    axes[i].imshow(imgs[i]); axes[i].axis(\"off\"); axes[i].set_title(f\"{dirs[i]}\");\n",
    "plt.subplots_adjust(wspace=0.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b397ceda",
   "metadata": {},
   "source": [
    "# Further Ideas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95ac14c2",
   "metadata": {},
   "source": [
    "Instead of doing a fully end-to-end [x0, x1] distance, keep taking the distances between x0s, but also set\n",
    "those lines overlapping in x to have 0 distance.\n",
    "\n",
    "I don't know actually if this makes too much sense. What it would do is not separate for example an image with a caption which\n",
    "is very far underneath it to the right.\n",
    "\n",
    "It has the advantage that the distances in x0s are more uniform than e2e distances. A short line on the left will have the\n",
    "same x0 distance from any kind of line on the right, where as the e2e distance depends on the size of the line.\n",
    "\n",
    "It also has the advantage that it would be more robust in the case of lines within a column being split into several\n",
    "lines for formatting. For example: <The         big       house> can happen sometimes in a text, and sometimes this can\n",
    "be split into 3 separate lines by pymudpdf. If the gaps are big enough between the words there, and the sublines composing\n",
    "the line, then the e2e distances may not include them in the epx_neighbouroood of the surrounding lines.\n",
    "\n",
    "Actually it will because of the overlap.\n",
    "\n",
    "As we have seen the epx_x of 10 we need to separate in x is very small."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ogham",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
